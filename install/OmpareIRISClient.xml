<?xml version="1.0" encoding="UTF-8"?>
<Export generator="IRIS" version="24">
<Class name="ompare.Schedule">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>]]></Description>
<Super>%SYS.Task.Definition</Super>
<TimeChanged>66487,51930.541105</TimeChanged>
<TimeCreated>64118,65813.451823</TimeCreated>

<Property name="Environment">
<Description>
Logical development pipeline environment eg: "BASE","TEST","UAT","LIVE"
For example development is implemented in "BASE", deployed to "TEST" for user testing,
the patch is validated in "UAT", before being published to "LIVE"
Environment may also include platform versioning for example as a migration
project from Cache2010_BASE to IRIS2019_BASE</Description>
<Type>%String</Type>
<Required>1</Required>
<Parameter name="MINLEN" value="1"/>
</Property>

<Property name="Namespaces">
<Description>
Comma seperated list of Available Namespaces to execute runners within
Supports trailing wild-cards for example INST-* will match "INST-MARS" and "INST-LUNAR"
"*" on its own would match ALL namesapces
Supports leading "-" (minus character) to exclude items in list
For example: *,-INST-LUNAR
eg: "USER,OBSERVER,INTEG-MARS,INTEG-LUNAR,INST-MARS"</Description>
<Type>%String</Type>
<Required>1</Required>
<Parameter name="MAXLEN" value="1500"/>
<Parameter name="MINLEN" value="3"/>
</Property>

<Property name="RunSourceHandlers">
<Description>
When the schedule runs should is profile the selected namespaces for Classes, Routines, Ensemble Lookup Tables, etc
to generate "Signature" / "Fingerprint" of content</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ExportToFile">
<Description>
When the schedule runs should the current "Signatures" for content be exported to the filesystem</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ExportDirectory">
<Description>
The directory where files for "Signatures" and "Source" are exported to</Description>
<Type>%String</Type>
<Parameter name="MAXLEN" value="220"/>
</Property>

<Property name="ExportCompression">
<Type>%Boolean</Type>
<InitialExpression>1</InitialExpression>
</Property>

<Property name="OverwriteSourceOnReLoad">
<Description>
In completed development a signature should match content it is generated from
However when developing new or extending existing SourceHandlers 
inconsistent Source can get introduced to reporting server
This flag allows Source for a signature to be "corrected"
as SourceHandler implementation is itterated and tested on the reporting server.</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
</Property>

<Method name="ExportDirectorySet">
<Description>
Correct the Path set via Task Schedule Web Page</Description>
<FormalSpec>val</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if val="" set i%ImportDirectory=val Quit $$$OK
	if $zcvt($SYSTEM.Version.GetOS(),"U")="UNIX" {
		if $E(val,*)'="/" {
			// Unix / Linux without trailing directory character
			set val=val_"/"
		}
	} elseif $E(val,*)'="\" {
		// Assume windows without trailing directory character
		set val=val_"\"
	}
	set i%ExportDirectory=val
	Q $$$OK
]]></Implementation>
</Method>

<Property name="BackupSourceCode">
<Description>
Flag to indicate whether a standard export of source code should be taken from each namespace of interest </Description>
<Type>%Boolean</Type>
</Property>

<Property name="ImportFromFile">
<Description>
When the schedule runs should signatures and source be imported (from remote systems).</Description>
<Type>%Boolean</Type>
</Property>

<Property name="ImportDirectory">
<Description>
The directory where files for "Signatures" and "Source" are imported from</Description>
<Type>%String</Type>
<Parameter name="MAXLEN" value="220"/>
</Property>

<Property name="DiscardProfileData">
<Description>
For a non-reporting instance
Clear SourceCode profile signatures and data prior to running the schedule
Clear SourceCode profile signatures and data prior to running the schedule
ie: After export files for signatures and source code has been written
Caution - When Enabled on a Reporting Server this will
Also clear Signature data collected from other systems</Description>
<Type>%Boolean</Type>
</Property>

<Method name="ImportDirectorySet">
<Description>
Correct the Path set via Task Schedule Web Page</Description>
<FormalSpec>val</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if val="" set i%ImportDirectory=val Quit $$$OK
	if $zcvt($SYSTEM.Version.GetOS(),"U")="UNIX" {
		if $E(val,*)'="/" {
			// Unix / Linux without trailing directory character
			set val=val_"/"
		}
	} elseif $E(val,*)'="\" {
		// Assume windows without trailing directory character
		set val=val_"\"
	}
	set i%ImportDirectory=val
	Q $$$OK
]]></Implementation>
</Method>

<Property name="ReImportUpdatedFiles">
<Description>
Flag to control whether files that have been imported previously should be reprocessed IF the filesystem timestamp has a newer modified datetime.</Description>
<Type>%Boolean</Type>
</Property>

<Property name="DeleteImportedFiles">
<Description>
Flag to control whether files that have been processed for import should be deleted from the Import Directory</Description>
<Type>%Boolean</Type>
</Property>

<Property name="RetainExportDays">
<Description>
Number of days to retain files containing "Signatures" and "Source" that have been exported to the Export Directory</Description>
<Type>%Integer</Type>
</Property>

<Property name="RetainSigSrcHistoricVersions">
<Description><![CDATA[
Number of historic versions to retain of global data for Signatures and Source snapshots
Set to "0" if we do not wish to hold historic data in globals for this system.<br/>
Set to "-1" to prevent analysis to discard obsolete source code entries. Useful for ECP mapped systems.]]></Description>
<Type>%Integer</Type>
</Property>

<Property name="EnableLogging">
<Description>
Switch to control whether SourceHandlers provide verbose logging during analysis of namespaces
Where a source handler generates "Signatures" and "Source" snapshots.</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
<Required>1</Required>
</Property>

<Property name="IncludeSourceCode">
<Description>
Switch used by SourceHandlers to control whether to include Source Information. ie: Data that can be exported into "Source" Files</Description>
<Type>%Boolean</Type>
<InitialExpression>0</InitialExpression>
<Required>1</Required>
</Property>

<Property name="Debug">
<Description>
Use by Schedule for verbose logging during Task Processing
A Cache schedule can be configured to send output to a file</Description>
<Type>%Boolean</Type>
</Property>

<Parameter name="ExportSignaturePrefix">
<Description>
The file prefix use for Exporting "Signature" files
The file prefix used to identify Import "Signature" files for processing</Description>
<Default>SrcUtilDataSig</Default>
</Parameter>

<Parameter name="ExportSourcePrefix">
<Description>
The file prefix use for Exporting "Source" files
The file prefix used to identify Import "Source" files for processing </Description>
<Default>SrcUtilDataSrc</Default>
</Parameter>

<Property name="STDOUT">
<Description>
Device to send debugging information to</Description>
<Type>%String</Type>
<Internal>1</Internal>
<Private>1</Private>
</Property>

<Property name="%PerNamespaceSourceHandlers">
<Description>
Enforced list SourceHandlers to run in each namespace
If set this list is used instead of searching for subclasses of SourceHandler Base
Useful for Mirrored environments when run on Backup Mirror</Description>
<Type>%String</Type>
<MultiDimensional>1</MultiDimensional>
</Property>

<Property name="%SystemSourceHandlers">
<Description>
Enforced list SourceHandlers to run once
If set this list is used instead of searching for subclasses of SourceHandler Base
Useful for Mirrored environments when run on Backup Mirror</Description>
<Type>%String</Type>
<MultiDimensional>1</MultiDimensional>
</Property>

<Property name="SrcVersionTokenStart">
<Description>
Source control systems may update a token in source code
with the brahc and version of code being checked-in
To filter out this sequence set the token start sequence used  </Description>
<Type>%String</Type>
<InitialExpression>"$I"_"d"</InitialExpression>
</Property>

<Property name="SrcVersionTokenEnd">
<Description>
As with property SrcVersionTokenStart, to filter out version string added to code
by source control system set the token end sequence</Description>
<Type>%String</Type>
<InitialExpression>"$"</InitialExpression>
</Property>

<Property name="SrcVersionParameter">
<Type>%String</Type>
<InitialExpression>"SrcVer"</InitialExpression>
</Property>

<Parameter name="ExportItemTypes">
<Description>
Used by GenerateBackupSourceCode</Description>
<Default>*.CLS,*.MAC,*.INC,*.RUL,*.HL7,*.AST</Default>
</Parameter>

<Method name="OnTask">
<Description><![CDATA[
Entry method called by IRIS TaskScheduler for processing.<br/>
<h3>Profiling Source code</h3>
<p>Searches for Classes that implement ompare.SourceHandler.Base.
For each namespace configured on the Schedule, run each SourceHandler.
Each source handler is responsible for building and storing signatures and optionally an extract of source code (eg: Content of a method)
</p>
<p>
<h3>Exporting Signatures</h3>
Builds a Signature file in the Export Directory that can be imported into other systems for reporting.</br>
Builds a Source file in the Export Directory that can be imported into other systems for Source Comparison details.</br>
Exported files are gzip compressed for efficent transfer between systems.</br>
Export Signature files have the filename convention
<example>
[ExportSignaturePrefix] + [Environment] + [CCYYMMDDHHMM] + ".gz"

SrcUtilDataSigTESTX201608011247.gz

Where:
  ExportSignaturePrefix = "SrcUtilDataSig"
  Environment = "TESTX"
  CCYYMMDDHHMM = 2016-08-01 12:47
</example>
Export Source files have the filename convention
<example>
[ExportSourcePrefix] + [Environment] + [CCYYMMDDHHMM] + ".gz"

SrcUtilDataSrcTESTX201607291247.gz

Where:
  ExportSignaturePrefix = "SrcUtilDataSrc"
  Environment = "TESTX"
  CCYYMMDDHHMM = 2016-07-29 12:47
</example>
</p>
<h3>Purge Exports</h3>
Files older than the configured numnber of days will be automatically deleted from the Export directory.
Controls the volume of data left on the filesystem by the schedule.
</p>
<h3>Importing Signatures</h3>
Identifies Signatures file in the Import Directory for import.
<h4>Rules of import</h4><li>
<li>If data is newer in time but for the same day as Current information, then the current information will be overwritten</li>
<li>If data is older in time but for the same day as Current information, the import data will be discarded</li>
<li>If data is for a newer day than the Current information. The current information will be moved to a historic view and new data imported as Current.</li>
<li>If data is older than current and where there is no historic record for the day, the data will be imported to the historic view and current data is unchanged</li>
<li>If data is older than current but where there is already historic data and the import data is newer in time, the historic data will be overwritten</li>
<li>If data is older than current but where there is already historic data and the import data is older in time, the import data is discarded and the historic data is unchanged</li>
</ul>]]></Description>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	set stdout=$IO
	set tSC=$$$OK
	// Initialise process
	Kill ^||Data,^||DataSrc
	
	// Check that this task is not already running
	Lock +^ompare.Schedule:2
	Quit:'$T $$$ERROR(5001,"Task already running") // Task already running so exit
	
	do ..DebugLine("******************************************")
	do ..DebugLine("  Schedule Starting "_$ZDT($H,3))
	do ..DebugLine("******************************************")
	
	// Delete all previous reporting data
	if ..DiscardProfileData {
		do ..DebugLine("Initialise... Remove previous Profile Data requested")
		Do ..PurgeProfileData()	
	}
	
	// Convenience syntax. Reformat Namespace List
	// Expand "*" to all namespaces
	// Expand "-[Namespace]" to strip the namespace from the list
	// Tests each namespace exists
	do ..DebugLine("Configured Namespace List = "_..Namespaces)
	set nslen=$L(..Namespaces,",")
	kill nslist
	for i=1:1:nslen {
		set ns=$ZSTRIP($Piece(..Namespaces,",",i),"<>W")
		continue:ns=""
		set nsprefix=$Piece(ns,"*")
		if $E(ns,*)="*",$E(ns,1)'="-" {
			if ns="*" {
				do ..DebugLine("Expanding namespace list for ALL (""*"")")
			} else {
				do ..DebugLine("Expanding namespace list starting with prefix ("""_nsprefix_""")")
			}
							
			// ADD ALL namespaces to the list
			set nsrs=##class(%ResultSet).%New("%SYS.Namespace:List")
			if nsrs.Execute(0,1)  // Exclude remote and do not connect
			{
				for {
					quit:'nsrs.Next()
					set ns=nsrs.Data("Nsp")
					continue:ns=""
					if nsprefix="" {
						set nslist(ns)=""
						continue
					}
					if nsprefix=$Extract(ns,1,$Length(nsprefix)) {
						set nslist(ns)=""
						continue
					}
				}
			}
			set nsrs=""
			continue	
		}
		// Minus prefix = Remove Namespace from List
		if $E(ns,1)="-" {
			// Removed the leading minus sign
			set ns=$E(ns,2,*)
			// Prefix has no leading minus sign or trailing wild card
			set nsprefix=$Piece(ns,"*")
			continue:ns=""
			// Exact Match for Namespace
			if $E(ns,*)'="*" {
				if '##class(%SYS.Namespace).Exists(ns) {
					do ..DebugLine("Ignoring Exclude namespace rule ""-"_ns_""". Namespace does not exist.")
					continue
				} else {
					do ..DebugLine("Excluding namespace """_ns_"""")
					kill nslist(ns)  // remove a previously added entry
					continue		
				}
			} elseif $E(ns,*)="*",nsprefix'="" {
				// Wild Card processing
				do ..DebugLine("Wild Card Proceesing for rule -"_ns)
				set nsrs=##class(%ResultSet).%New("%SYS.Namespace:List")
				if nsrs.Execute(0,1)  // Exclude remote and do not connect
				{
					for {
						quit:'nsrs.Next()
						set nsq=nsrs.Data("Nsp")
						continue:nsq=""

						if nsprefix=$Extract(nsq,1,$Length(nsprefix)) {
							// Delete previous entry
							do ..DebugLine("Excluding namespace """_nsq_"""")
							kill nslist(nsq)
							continue
						}
					}
				}
				set nsrs=""
			}
			
			continue	
		}
		// Exact Match for namespace
		if '##class(%SYS.Namespace).Exists(ns) {
			do ..DebugLine("Ignoring Include namespace rule "_ns_""". Namespace does not exist.")
			continue	
		}
		do ..DebugLine("Including namespace """_ns_"""")
		set nslist(ns)=""
	}
	// Now reassemble namespace list for normal processing
	set (ns,nslist)=""
	for {
		set ns=$Order(nslist(ns))
		quit:ns=""
		set nslist=nslist_ns_","
	}
	do ..DebugLine("Expanded / Resolved Namespace List = "_nslist)
		
	if ..RunSourceHandlers {
	
		if $O(..%PerNamespaceSourceHandlers(""))="",$O(..%SystemSourceHandlers(""))="" {
			// Discover deployed Source handlers
			set rs=##class(%ResultSet).%New()
			set rs.ClassName="%Dictionary.ClassDefinition"
			set rs.QueryName="SubclassOf"
			if rs.Execute("ompare.SourceHandler.Base") {
				while rs.Next() {
					set sourceHandler=rs.Data("Name")
					do ..DebugLine("Query SubclassOf SourceHandler.Base: "_sourceHandler)
					continue:sourceHandler=""
					
					// Check whether this is a per-namespace
					//InvokePerNamespace
					set perNamespace=1  // default to true if not overriden in sub-class
					set perNamespace=$PARAMETER(sourceHandler,"InvokePerNamespace")
					if perNamespace=1 {
						do ..DebugLine("Register per Namespace SourceHandler "_sourceHandler)
						set perNamespaceSourceHandlers(sourceHandler)=""
					} else {
						do ..DebugLine("Register per System SourceHandler "_sourceHandler)
						set systemSourceHandlers(sourceHandler)=""
					}
					set parameter=""
				}	
			}
			do rs.Close()
			set rs=""
		} else {
			set sourceHandler=""
			for {
				set sourceHandler=$O(..%PerNamespaceSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				if ##class(%Dictionary.CompiledClass).%ExistsId(sourceHandler) {
					set perNamespaceSourceHandlers(sourceHandler)=""
				} else {
					do ..DebugLine("Skipping unknown PerNamespaceSourceHandlers """_sourceHandler_"""")
				}
			}
			set sourceHandler=""
			for {
				set sourceHandler=$O(..%SystemSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				if ##class(%Dictionary.CompiledClass).%ExistsId(sourceHandler) {
					set systemSourceHandlers(sourceHandler)=""
				} else {
					do ..DebugLine("Skipping unknown SystemSourceHandlers """_sourceHandler_"""")
				}	
			}
		}	
		if ..RetainSigSrcHistoricVersions>0 {
			// Also initialises current Data
			Do ..SaveHistoricData(..Environment)
		} else {
			// Initialise Current Data
			// Delete ALL current Data in expectation of new
			// We don't want a combination of OLD + NEW
			Kill ^ompare("Data",..Environment)
		
			// Initalise DateTime for new Data
			// Format
			//   Date
			//   Time
			//   Server
			//   Instance
			set ^ompare("Data",..Environment)=$TR($P($H,"."),",","^")_"^"_$TR($SYSTEM,":","^")
				
		}
		if ..OverwriteSourceOnReLoad {
			do ..DebugLine("Skipping BuildExistingDataSrcList - OverwriteSourceOnReLoad flag is set")
		} else {
			Do ..BuildExistingDataSrcList()
		}
	
		set ns=""
		for {
			set ns=$Order(nslist(ns))
			quit:ns=""
			
			// For each Sub-classes of ompare.SourceHandler.Base"
			set sourceHandler=""
			for {
				set sourceHandler=$Order(perNamespaceSourceHandlers(sourceHandler))
				quit:sourceHandler=""
				try {
					Kill ^||Data
					// Build up new ^||Data for signatures and update ^||DataSrc
					do ..DebugLine("Running SourceHandler "_sourceHandler_" in namespace "_ns_" IncludeSourceCode="_..IncludeSourceCode)
					Do $CLASSMETHOD(sourceHandler,"IndexNamespace",ns,..EnableLogging,..IncludeSourceCode)
					
					Merge ^ompare("Data",..Environment,ns)=^||Data
							
				} catch errobj {
					// Error in BACKUP
					// Catches intentional <ENDOFFILE>
    				if ..Debug {
	    				u stdout WRITE "In Catch block standard export of source code",!
						u stdout WRITE "  Error Name:",errobj.Name,!
    					u stdout WRITE "  Error code: ",errobj.Code,!
    					u stdout WRITE "  Error location: ",errobj.Location,!
    					u stdout WRITE "  Error data:",errobj.Data,!
	    			}	
				}
				Kill ^||Data
			}
		}
	
		// Now run system wide Source Handlers
		set sourceHandler=""
		for {
			set sourceHandler=$Order(systemSourceHandlers(sourceHandler))
			quit:sourceHandler=""
			try {
				Kill ^||Data
				do ..DebugLine("Running System Wide Source Handlers SourceHandler "_sourceHandler_" for system context ")
				Do $CLASSMETHOD(sourceHandler,"IndexNamespace",ns,..EnableLogging,..IncludeSourceCode,..SrcVersionTokenStart,..SrcVersionTokenEnd)
			
				Merge ^ompare("Data",..Environment,ns)=^||Data

			} catch errobj {
				// Error in BACKUP
				// Catches intentional <ENDOFFILE>
    			do ..DebugLine("In Catch block System Wide Source Handlers")
				do ..DebugLine("  Error Name:"_errobj.Name)
    			do ..DebugLine("  Error code: "_errobj.Code)
    			do ..DebugLine("  Error location: "_errobj.Location)
    			do ..DebugLine("  Error data:"_errobj.Data)
	    		
			}
			Kill ^||Data
		}
	
		Do ..ApplyChangesDataSrc(..OverwriteSourceOnReLoad)
		Kill ^||DataSrc
	
		// Truncate Obsolete Historic Signatures
		// Truncate Obsolete Src entries no longer needed because they are no longer referenced by a signature on this system
		Do ..PurgeSigSource(..RetainSigSrcHistoricVersions,..Debug)
		// End RunSourceHandlers - Processing
	}
	// Generate Export Files if necessary
	do {
		Quit:'..ExportToFile
		if '##class(%File).DirectoryExists(..ExportDirectory)
		{
			set tSC=$$$ERROR(5001,"ExportDirectory "_..ExportDirectory_" not found")
			Quit
		}
		// CCYYMMDDHHSS
		set dateh=$TR($ZDT($H,8,2,4,0)," :")
		set datafile=..ExportDirectory_$S($E(..ExportDirectory,*)'?1(1"/",1"\"):$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"),1:"")_..#ExportSignaturePrefix_..Environment_dateh_$S(..ExportCompression:".gz",1:".tx")
		do ..DebugLine("Exporting Signatures to filepath "_datafile)
		set opened=0
		if ..ExportCompression {
			Open datafile:("NWS":/GZIP=1):2
			set opened=$T
		} else {
			Open datafile:("NWS"):2
			set opened=$T
		}
		if opened {
			use datafile Do ..ExportDataToDevice(..Environment)
		} else {
			do ..DebugLine("Unable to create file "_datafile)	
		}
		close datafile
		
		set datafile=..ExportDirectory_$S($E(..ExportDirectory,*)'?1(1"/",1"\"):$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"),1:"")_..#ExportSourcePrefix_..Environment_dateh_$S(..ExportCompression:".gz",1:".tx")
		do ..DebugLine("Exporting Source to filepath "_datafile)
		set opened=0
		if ..ExportCompression {
			Open datafile:("NWS":/GZIP=1):2
			set opened=$T
		} else {
			Open datafile:("NWS"):2
			set opened=$T
		}
		if opened {
			use datafile Do ..ExportDataSrcToDevice()
		} else {
			do ..DebugLine("Unable to create file "_datafile)		
		}
		close datafile
		
	} while (0)
	// Purge old export files based on schedule policy
	if ..RetainExportDays?1.2N,($L(..ExportDirectory)>2),##class(%File).DirectoryExists(..ExportDirectory) {
		Do ..PurgeOldFiles(..ExportDirectory,..RetainExportDays,..Debug)
	}
	
	do {
		Quit:'..ImportFromFile
		if $L(..ImportDirectory)<2 {
			do ..DebugLine("ImportDirectory parameter is Empty")
			Quit
		}
		if '##class(%File).DirectoryExists(..ImportDirectory) {
			do ..DebugLine("Import Directory "_..ImportDirectory_" not accessible")
			Quit
		}
		Do ..ProcessImportDirectory()
	} while (0)
	
	// Do we require a standard export of source code from each named namespace
	if ..BackupSourceCode {
		set ns=""
		for {
			set ns=$Order(nslist(ns))
			quit:ns=""	
			
			try {
				// Build up new ^||Data for signatures and update ^||DataSrc
				do ..DebugLine("Backing up source code in namespace "_ns)
				
				set tSC=..GenerateBackupSourceCode(ns,..ExportDirectory,..Environment)
				if $$$ISERR(tSC) {
					do ..DebugLine("Error generating Backup for Source code in namespace "_ns)
					do ..DebugLine($SYSTEM.Status.GetOneErrorText(tSC))
				}
							
			} catch errobj {
				// Error in BACKUP
				// Catches intentional <ENDOFFILE>
    			do ..DebugLine("In Catch block Backup Source Code")
				do ..DebugLine("  Error Name:"_errobj.Name)
    			do ..DebugLine("  Error code: "_errobj.Code)
    			do ..DebugLine("  Error location: "_errobj.Location)
    			do ..DebugLine("  Error data:"_errobj.Data)
	    			
			}
		}
	}
	
	// Delete any reporting data generated by this schedule
	if ..DiscardProfileData {
		do ..DebugLine("Clean Up... Remove Profile Data requested")
		Do ..PurgeProfileData()	
	}
	
	do ..DebugLine("*******************************************")
	do ..DebugLine("  Schedule Completed "_$ZDT($H,3))
	do ..DebugLine("*******************************************")
	
	// The unlocking is useful when a schedule is run
	// programatically from a command line or process that
	// does not exit after completion.
	Lock -^ompare.Schedule
	
	Quit $$$OK
]]></Implementation>
</Method>

<Method name="SaveHistoricData">
<Description><![CDATA[
Back-up current data if older than new generated / imported data
Truncates current or historic data to be replaced
If a newer version of data exists for the current day - this will simply be overwritten with latest data
Return Values<ul>
<li>0 = Abandon the Import. Data in file is obsolete</li>
<li>1 = Continue with Export / Import. Write to Current Data</li>
<li>2 = Continue with Import. Write to Historic Data</li>
</ul>]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>environment="",dateOfData=+$H,timeOfData=$P($H,",",2),serverAndInstance=$TR($SYSTEM,":","^")</FormalSpec>
<Implementation><![CDATA[
	quit:environment="" 0
	quit:dateOfData="" 0
	// Defaults: dateOfData, timeOfData and serverAndInstance
	
	set previousDate=+$P($G(^ompare("Data",environment)),"^")
	set previousTime=+$P($G(^ompare("Data",environment)),"^",2)
	set historicTime=+$P($G(^ompare("History",dateOfData,environment)),"^",2)
	set previousServerAndInstance=$P($G(^ompare("Data",environment)),"^",3,99)
	
	if previousDate<dateOfData {
		//W !,"SaveHistoricData = previousDate<dateOfData"
		// Trucate any previous historic data for this date
		kill ^ompare("History",previousDate,environment)
		
		// Move to historic if current data exists
		// Copies both date and time to historic node
		merge ^ompare("History",previousDate,environment)=^ompare("Data",environment)
		
		// Delete current Data in expectation of new
		Kill ^ompare("Data",environment)
		
		// Initalise DateTime for new Data
		set ^ompare("Data",environment)=dateOfData_"^"_timeOfData_"^"_serverAndInstance
		
		// Proceed with Export / Import
		Quit 1
		
	} elseif previousDate=dateOfData {
		//W !,"SaveHistoricData = previousDate=dateOfData"
		if previousTime<timeOfData {
			// Overwrite current Data
			// Delete current data in expectation of new
			Kill ^ompare("Data",environment)
			
			// Initalise DateTime for new Data
			set ^ompare("Data",environment)=dateOfData_"^"_timeOfData_"^"_serverAndInstance
			
			Quit 1	
		} else {
			// Abandon Import - Data saved in database is newer than import file
			Quit 0
		}
	} elseif previousDate>dateOfData {
		//W !,"SaveHistoricData = previousDate>dateOfData"
		// Write historic records
		if historicTime<timeOfData {
			// Overwrite historic Data
			Kill ^ompare("History",dateOfData,environment)
			
			// Initalise DateTime for historic Data
			set ^ompare("History",dateOfData,environment)=dateOfData_"^"_timeOfData_"^"_previousServerAndInstance
			
			Quit 2
			
		} else {
			//W !,"H4"
			// Abandon Import 
			Quit 0	
		}
	}
	
	Quit 0
]]></Implementation>
</Method>

<Method name="BuildExistingDataSrcList">
<Description>
Build a process private list of existing code signatures and their last know active date</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	Kill ^||DataSrc
	set sig=""
	for {
		set sig=$Order(^ompare("DataSrc",sig))
		quit:sig=""
		// By default if any previously existing signatures do not exist apply todays date
		set date=$G(^ompare("DataSrc",sig),+$H)
		set ^||DataSrc(sig)=date
	}
]]></Implementation>
</Method>

<Method name="ApplyChangesDataSrc">
<Description>
Updates the current date held against source code signatures
Saves additional new source code</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>overwriteSourceOnReLoad=0</FormalSpec>
<Implementation><![CDATA[
	// Using iterate instead of block merge to reduce Journal impact
	set sig=""
	for {
		set sig=$O(^||DataSrc(sig))
		quit:sig=""
		// remove / truncate if required
		kill:overwriteSourceOnReLoad ^ompare("DataSrc",sig)
		if $Data(^ompare("DataSrc",sig))=0 {
			merge ^ompare("DataSrc",sig)=^||DataSrc(sig)  // New data
		} elseif ($G(^ompare("DataSrc",sig))<^||DataSrc(sig)){
			set ^ompare("DataSrc",sig)=^||DataSrc(sig)  // Update still in use date
		} else {
			// No change in date used.
			// Obsolete information from current date but still maybe relavent for historic data
		}
	}
]]></Implementation>
</Method>

<Method name="ExportDataToDevice">
<Description>
Output Source Signatures to the open device (gzip file or Terminal)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>environment=""</FormalSpec>
<Implementation><![CDATA[
	quit:environment=""
	
	W "ENV|",$TR(environment,"|"),"|",$TR($G(^ompare("Data",environment)),"^","|"),!
	set namespace=""
	for {
		set data=""
		set namespace=$Order(^ompare("Data",environment,namespace),+1,data)
		quit:namespace=""

		W "NSP|",$TR(namespace,"|"),"|",$TR(data,"^","|"),!  // Append as pipe delimted data from global
		
		set type=""
		for {
			set type=$Order(^ompare("Data",environment,namespace,type))
			quit:type=""
			
			set typename=""
			for {
				set typename=$Order(^ompare("Data",environment,namespace,type,typename),+1,data)
				quit:typename=""
				
				W "TYP|",$TR(type,"|"),"|",$TR(typename,"|"),"|",data,!
				
				set subtype=""
				for {
					set subtype=$Order(^ompare("Data",environment,namespace,type,typename,subtype))
					quit:subtype=""
				
					set subtypename=""
					for {
						set subtypename=$Order(^ompare("Data",environment,namespace,type,typename,subtype,subtypename),+1,data)
						quit:subtypename=""
					
						W "SUB|",$TR(subtype,"|"),"|",$TR(subtypename,"|"),"|",data,!
					}
				}
			}
			
		}
	}
	W "END|||",!
]]></Implementation>
</Method>

<Method name="ExportDataSrcToDevice">
<Description>
Output Source snapshot to the open device (gzip file or Terminal)</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	set sig=""
	for {
		set data=""
		set sig=$O(^ompare("DataSrc",sig),+1,data)
		quit:sig=""
		W "S|",sig,"|",data,!
		
		set line=""
		for {
			set data=""
			set line=$O(^ompare("DataSrc",sig,line),+1,data)
			quit:line=""
			W "L|",data,!
		}
	}
	W "END|||",!
]]></Implementation>
</Method>

<Method name="PurgeOldFiles">
<Description><![CDATA[
Removes old export files from the filesystem
Expects files in format
<example>
ExportSignaturePrefix + Environment + CCYYMMDDHHMM + ".gz"
ExportSourcePrefix + Environment + CCYYMMDDHHMM + ".gz"
</example>
For example
<example>
SrcUtilDataSigUAT201601011023.gz
SrcUtilDataSrcUAT201601011245.gz
</example>]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>directory,retain=5,debug=0</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if debug {
		W !,"PurgeOldFiles called."
		W !,"  >> Directory=",directory
		W !,"  >> Retain Days=",retain
	}
	
	set tSC=$$$OK
	set deleteBeforeHorolog=$H-retain
	for prefix=..#ExportSignaturePrefix,..#ExportSourcePrefix {
		// File ResultSet
		set rs=##class(%ResultSet).%New()
		set rs.ClassName="%File"
		set rs.QueryName="FileSet"
		set tSC=rs.Execute(directory,prefix_"*.gz;"_prefix_"*.tx",0)
		
		// Expect prefix + Environment + CCYYMMDDHHMM
		set tSC=$$$OK
		for {
			Quit:'rs.Next(.tSC)
			Quit:$$$ISERR(tSC)
			
			set path=rs.Data("Name")
			set filename=##class(%File).GetFilename(path)

			// Extracts the date part of the filename for comparison with todays date
			// Don't trust filesystem timestamp
			set ccyymmdd=$E(filename,*-14,*-7)
			if ccyymmdd'?8N {
				w:debug !,"Skipping file ",filename," invalid format"
				continue
			}
			set hd=$ZDH(ccyymmdd,8,,4,,,,,"")
			if hd<1 {
				w:debug !,"Skipping file ",filename," invalid format"
				continue
			}
			// Ignore files that should be retained
			if hd>=deleteBeforeHorolog {
				W:debug !,"Retaining file ",filename,". Within Retain ",retain," days."	
				continue
			}
			W:debug !,"Deleting file ",filename
			do ##class(%File).Delete(path)
		}
	}
	quit tSC
]]></Implementation>
</Method>

<Method name="Test1">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	set o=##class(ompare.Schedule).%New()
	set o.Environment="VAL"
	set o.Namespaces="INTEG-TCL"
	set o.ExportToFile=1
	set o.ExportDirectory="/trak/lab/traktemp"
	set o.RetainExportDays=5
	set o.EnableLogging=0
	set o.IncludeSourceCode=1
	set o.Debug=0
	set tSC=o.OnTask()
	do $SYSTEM.Status.DisplayError(tSC)
]]></Implementation>
</Method>

<Method name="Test2">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	
	set directory="/trak/lab/traktemp/"
	set extension=".gz"
	
	// Normal format test Signature
	set datetime=$TR($ZDT($H,8,2,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"1_SIG_PASS"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	//set dateh=$TR($ZDT($H,8,2,4,0)," :")
	// Normal format test Source code
	set path=directory_..#ExportSourcePrefix_"2SRC_PASS"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// Abnormal prefix test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_"ABC"_..#ExportSourcePrefix_"3PrefixFail"_datetime_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// File format date format test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"4DateFormatFail"_"datetime"_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	// File format date invalid test
	//set datetime=$TR($ZDT($H,8,,0,,4)," :")
	set path=directory_..#ExportSignaturePrefix_"5DateInvalidFail"_"9"_$E(datetime,2,12)_extension
	Open path:("NWS":/GZIP=1):2
	Quit:'$T
	Use path W !
	Close path
	
	//Do ..ProcessImportDirectory(directory,1,1)
	
	set o=##class(ompare.Schedule).%New()
	set o.Environment="TEST"
	set o.Namespaces="INTEG-TCL"
	set o.RunSourceHandlers=0
	set o.ExportToFile=0
	set o.ExportDirectory=""
	set o.ImportDirectory="/trak/lab/traktemp"
	set o.ImportFromFile=1
	set o.ReImportUpdatedFiles=1
	set o.DeleteImportedFiles=1
	set o.RetainExportDays=5
	set o.EnableLogging=0
	set o.IncludeSourceCode=0
	set o.Debug=1
	
	do o.ProcessImportDirectory()
	
	//set tSC=o.OnTask()
	//do $SYSTEM.Status.DisplayError(tSC)
]]></Implementation>
</Method>

<Method name="ProcessImportDirectory">
<Description>
Main method to start importing Signatures and Code Snapshot from Import Directory</Description>
<Implementation><![CDATA[
	Quit:..ImportFromFile=0
	if ..ImportFromFile=0 {
		W:..Debug !,"ImportFromFile disabled. End Process Import Directory."	
	}
	
	if ..ImportDirectory="" {
		W:..Debug !,"Import Directory is empty. End ProcessImportDirectory."
		quit
	}
	set ..ImportDirectory=..WithTrailingPathSeperator(..ImportDirectory)
	W:..Debug !,"Import Directory=",..ImportDirectory
	
	set tSC=$$$OK
	/// Only gzip files with the given prefix will be processed AND optionally deleted.
	for prefix=..#ExportSignaturePrefix,..#ExportSourcePrefix {
		// File ResultSet
		set rs=##class(%ResultSet).%New()
		set rs.ClassName="%File"
		set rs.QueryName="FileSet"
		set tSC=rs.Execute(..ImportDirectory,prefix_"*.gz;"_prefix_"*.tx",0)
		if $$$ISERR(tSC) {
			W:..Debug !,$SYSTEM.Status.GetOneErrorText(tSC)	
			continue
		}
		
		// Expect prefix + Environment + CCYYMMDDHHMM
		set tSC=$$$OK
		for {
			Quit:'rs.Next(.tSC)
			if $$$ISERR(tSC) {
				W:..Debug !,$SYSTEM.Status.GetOneErrorText(tSC)	
				continue
			}

			set path=rs.Data("Name")
		
			W:..Debug !,"Verify file ",path
			
			set filename=##class(%File).GetFilename(path)

			// Extracts the date part of the filename for comparison with todays date
			// Don't trust filesystem timestamp
			set ccyymmddmm=$E(filename,*-14,*-7)_" "_$E(filename,*-6,*-5)_":"_$E(filename,*-4,*-3)
			if ccyymmddmm'?8N1" "2N1":"2N {
				w:..Debug !,"Skipping file ",filename," invalid date format"
				if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				}
				continue
			}
			set hd=$ZDTH(ccyymmddmm,8,2,4,,,,,,"")
			if ((+hd<1)||(+hd>94599)) {
				w:..Debug !,"Skipping file ",filename," invalid date value"
				if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				}
				continue
			}
			// Ignore files that have already been imported
			set dateh=##class(%File).GetFileDateModified(path,1)
			set dateh=($P(dateh,",")*86400)+$P(dateh,",",2)  // Convert to seconds
			
			set dateTimeChanged=$Get(^ompare("ImportedModified",filename))
			// Re-importing modified files enabled
			if ..ReImportUpdatedFiles {
				if dateTimeChanged'="" {
					if dateh=dateTimeChanged {
						W:..Debug !,"Skipping previous processed file ",path," - Modified date unchanged"
						if ..DeleteImportedFiles {
							W:..Debug !,"Deleting file ",path
							do ##class(%File).Delete(path)	  
						}
				  		continue
					} elseif dateh<dateTimeChanged {
						W:..Debug !,"Skipping previous processed file ",path," - Modified date older"
						if ..DeleteImportedFiles {
							W:..Debug !,"Deleting file ",path
							do ##class(%File).Delete(path)	  
						}
				  		continue	
					}
				}
			} else {
				if $Data(^ompare("ImportedModified",filename))
				{
					W:..Debug !,"Skipping previously processed file ",path
					if ..DeleteImportedFiles {
						W:..Debug !,"Deleting file ",path
						do ##class(%File).Delete(path)	  
				  	}
					continue
				}	
			}
			
			//TODO Process File			
			if prefix=..#ExportSignaturePrefix {
				Do ..ImportDataFromDevice(path,,..Debug)
			} else {
				Do ..ImportDataSrcFromDevice(path,..Debug,..OverwriteSourceOnReLoad)	
			}
			
			set ^ompare("ImportedModified",filename)=dateh  // $H date converted to seconds
			
			if ..DeleteImportedFiles {
				W:..Debug !,"Deleting file ",path
				do ##class(%File).Delete(path)	  
			}
			
		}
	}
	quit tSC
]]></Implementation>
</Method>

<Method name="ImportDataFromDevice">
<Description>
Import Signature file from Import directory device (filename)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>device=$IO,alias="",logging=0</FormalSpec>
<Implementation><![CDATA[
	set tSC=$$$OK
	set stdout=$IO
	// If device is a directory parse the directory for individual files with 

	/*
	ENV|VAL|64125|39580|Server|Instance  // Trust the Date and Time in the environment header for data insertion
	  P2 = ENVIRONMENT ALIAS on schedule eg: "VAL"
	  P3 = $H Date
	  P4 = $H Time
	  P5 = Server Name at time of analysis ie: May be clustered / mirrored / shadowed
	  P6 = Cache Instance Name - May be multiple instances on one cache server (At time of analysis)
	  
	  see: ompare.SourceHandler.Namespace
	NSP|INTEG-TCL|64125|39580|
	  P2 = Namespace name
	  P3 = $H Date of analysis
	  P4 = $H Time of analysis
	  P5 = Source Control Class
	  P6 = CCR Is Locked
	  P7 = Perforce Disconnected
	  P8 = Current Ensemble Production Name
	  P9 = CCR Organisation
	  P10= CCR System
	  P11= CCR Environment
	  P12= Role eg: INSTR, LABDB, INTEG
	  P13= Tags eg: CHIRP, EMPI, CHEMOCARE
	  P14= Depreciate Comment eg: Use Health Board specific namespace instead
	  
	TYP|C|CLNNHSW.CSAD|9gXg6Mi4x45TuF/3WOAuoxPGefE=
	SUB|M|AccessionNum|8FDHInI+JxJBKoH+kPM3FYGfc+g=
	*/
	// Check if file exists
	if device'=0 {
		if '##class(%File).Exists(device) {
			if logging u stdout w !,"File ",device," not found"	
			Quit
		}
		
		set fileExtension=$E(device,*-2,*)
		set datetime=$E(device,*-14,*-3)
		set environment=$E(device,$L(..#ExportSignaturePrefix)+1,*-15)
		if logging {
			u stdout W !,"Processing signature file"
			u stdout W !,"  From environment ",environment
			u stdout W !,"  Generated ",$E(datetime,1,4),"-",$E(datetime,5,6),"-",$E(datetime,7,8)," ",$E(datetime,9,10),":",$E(datetime,11,12)
		}
	
		set opened=0
		if fileExtension=".gz" {
			Open device:("RS":/GZIP=1):2
			set opened=$T
		} elseif fileExtension=".tx" {
			Open device:("RS"):2
			set opened=$T
		}
		if 'opened {
			if logging u stdout w !,"Unable to OPEN file "_device
			Quit	
		} else {
			if logging u stdout w !,"OPENed file "_device
		}
	}

	try {
		//TSTART
		// saveType
		//    When "0" obsolete date
		//    When "1" current Data
		//    When "2" Historic data
		// dateOfData
		//    Horolog Date from import file for environment
		set (env,nsp,typ,saveType,dateOfData,timeOfData)=""
		set race=0
		set maxRace=1000
		set cline=0
		for {
			Use device Read data:10
			if '$T {
				set race=race+1
				if race>maxRace {
					if logging u stdout w !,"Throwing error Race Conditon"
					THROW ##class(%Exception.StatusException).CreateFromStatus($$$ERROR(5001,"Race Condition"))
				}
				u stdout w !,"Bad read after:",!,"  p1=",p1,!,"  p2=",p2,!,"  p3=",p3,!,"  p4=",p4,!
				continue
			} else {
				set race=0				
				set cline=cline+1
				if logging>2 u stdout  W !,"Line:",cline
			}
			set p1=$P(data,"|")
			set p2=$P(data,"|",2)
			set p3=$P(data,"|",3)
			set p4=$P(data,"|",4,999)
			continue:p1=""
			
			if (p1="ENV") {
				if alias="" {
					set env=p2  // Trust the environment source from the file
				} else {
					set env=alias  // Override the environment value in the schedule for Testing OR Subscriptions
				}
				set (nsp,typ,typNam)=""
				continue:env=""
				
				
				// Trust the Date and Time in the environment header for data insertion
				// If the time for an imported file is older than the time for existing data for a given date skip the import
				set dateOfData=+p3
				// Date Validation
				continue:dateOfData<0
				continue:dateOfData>+$H  // More than todays date
				set timeOfData=+p4
				// Time validation
				continue:timeOfData<0
				continue:timeOfData>86399 // More than seconds in a day
				
				// Backup historic data, trucate historic data where necessary
				if logging u stdout w !,"Calling SaveHistoricData env=",env,", dateOfData=",dateOfData,", timeOfData=",timeOfData
				set saveType=..SaveHistoricData(env,dateOfData,timeOfData,$TR($Piece(p4,"|",2,999),"|","^"))
				if logging u stdout w !,"  saveType=",saveType
				if saveType=0
				{
					// Data is obsolete so ignore file contents
					set env=""
					if logging u stdout w !,"Ignoring obsolete data for environment ",env," for date ",$ZDT(dateOfData_","_timeOfData)
					continue		
				}				
			} elseif (p1="NSP") {
				continue:env=""
				set nsp=p2
				continue:nsp=""
				set (typ,typNam)=""
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp)=p3_"^"_$TR(p4,"|","^")
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""")="""_p3_"""^"_$TR(p4,"|","^")
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam)=p3_"^"_$TR(p4,"|","^")
				}
			} elseif (p1="TYP") {
				continue:env=""
				continue:nsp=""
				set typ=p2
				continue:typ=""
				set typNam=p3
				continue:typNam=""
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp,typ,typNam)=p4  // Type Signature Current
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""","""_typ_""","""_typNam_""")="""_p4_""""
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam)=p4  // Type Signature Historic
				}
				
			} elseif (p1="SUB") {
				continue:env=""
				continue:nsp=""
				continue:typ=""
				continue:typNam=""
				continue:p2="" // SUB Subtype code
				continue:p3="" // Sub type name
				continue:p4="" // Signature
				if saveType=1 {
					// Write Current Record
					set ^ompare("Data",env,nsp,typ,typNam,p2,p3)=p4  // SubType Signature Current
					if logging>1 u stdout w !,"set ^ompare(""Data"","""_env_""","""_nsp_""","""_typ_""","""_typNam_""","""_p2_""","""_p3_""")="""_p4_""""
				} elseif saveType=2 {
					// Write Historic Record
					set ^ompare("History",dateOfData,env,nsp,typ,typNam,p2,p3)=p4  // SubType Signature Historic
				}
			} elseif (p1="END") {
				quit
			}
		}
		// Code path occurs with END file
		// Required to mitigate issue with large GZIP files not detecting end of file on read
		///TCOMMIT
	} catch errobj {
		// Catches intentional <ENDOFFILE>
    	if errobj.Name'="<ENDOFFILE>",logging {
	    	u stdout WRITE "In Catch block Import Signature Code",!
			u stdout WRITE "  Error Name:",errobj.Name,!
    		u stdout WRITE "  Error code: ",errobj.Code,!
    		u stdout WRITE "  Error location: ",errobj.Location,!
    		u stdout WRITE "  Error data:",errobj.Data,!
	    	///TROLLBACK	
    	} else {
	    	/// Expected to hit EOF error
	    	///TCOMMIT	
    	}
	}
	Close:device'=0 device
	u stdout Write !,"End Import Signature File"
	Quit tSC
]]></Implementation>
</Method>

<Method name="ImportDataSrcFromDevice">
<Description>
Import Source file from Import directory device (filename)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>device=$IO,logging=0,overwriteSourceOnReLoad=0</FormalSpec>
<Implementation><![CDATA[
	set tSC=$$$OK
	set stdout=$IO

	// Check if file exists
	if device'=0 {
		if '##class(%File).Exists(device) {
			if logging u stdout W !,"File ",device," not found"	
			Quit
		}
		
		set fileExtension=$E(device,*-2,*)
		set datetime=$E(device,*-14,*-3)
		set environment=$E(device,$L(..#ExportSourcePrefix)+1,*-15)
		if logging {
			u stdout W !,"Processing signature file"
			u stdout W !,"  From environment ",environment
			u stdout W !,"  Generated ",$E(datetime,1,4),"-",$E(datetime,5,6),"-",$E(datetime,7,8)," ",$E(datetime,9,10),":",$E(datetime,11,12)
		}
	
		set opened=0
		if fileExtension=".gz" {
			Open device:("RS":/GZIP=1):2
			set opened=$T
		} elseif fileExtension=".tx" {
			Open device:("RS"):2
			set opened=$T
		}
		if 'opened {
			if logging u stdout W !,"Unable to OPEN file "_device
			Quit	
		} else {
			if logging u stdout W !,"File open "_device	
		}
	}
	
	try {
		//TSTART
		if logging u stdout w !,"In Transaction. Log Level=",logging
		
		set lineNum=0
		set (sig,date,line)=""
		set race=0
		set maxRace=1000
		for {
			Use device Read data:10
			if '$T {
				set race=race+1
				if race>maxRace THROW ##class(%Exception.StatusException).CreateFromStatus($$$ERROR(5001,"Race Condition"))
				continue
			} else {
				set race=0				
			}
			set lineNum=lineNum+1
			if logging>2 u 0 w !,lineNum //,":",$E(data,1,20)
			if $TR(data,$C(0,1,2,3,4,5,6,7,8,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31),"")'=data {
				u 0 w !,"BadChars in LineNum",lineNum
				for ctxt=0:1:$L(data) {
					for ttxt=0,1,2,3,4,5,6,7,8,11,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31 {
						if $C(ttxt)=$E(data,ctxt) u 0 w !,"  Charcode:",ttxt," at character ",ctxt	
					}	
				}
				u 0 w !,"  Sample BadContent",!,$E(data,1,20)
			}
			set p1=$P(data,"|")
			//set p2=$P(data,"|",2)
			//set p3=$P(data,"|",3)
			continue:p1=""
			
			if (p1="S") {
				
				set sig=$P(data,"|",2)
				set date=$P(data,"|",3)
				set line=0
				continue:sig=""
				// Work around for importing new code without date
				set:date="" date=+$H
				//continue:date=""
				
				set oldDate=+$G(^ompare("DataSrc",sig))
				if 'overwriteSourceOnReLoad,(oldDate>0) {
					if date>oldDate {
						// Update the date - Signature still in use
						set ^ompare("DataSrc",sig)=date
						// No need to re-import data so clear "sig" varible to ensure associated Source lines are skipped
						set sig=""
						set date=""
						continue
					}
				} else {
					// If overwriting - remove / truncate the previous source data
					kill:overwriteSourceOnReLoad ^ompare("DataSrc",sig)
					// Save the data - not seen before
					set ^ompare("DataSrc",sig)=date
					continue	
				}
			} elseif (p1="L") {
				continue:sig=""  // Discard Known Data
				continue:date=""	// Discard Known Data
				
				set line=line+1
				// Save the Source code line
				set ^ompare("DataSrc",sig,line)=$E(data,3,*)
				
			} elseif (p1="END") {
				// Terminate the file
				quit
			}	
		}
		// Code path occurs with END file
		// Required to mitigate issue with large GZIP files not detecting end of file on read
	} catch errobj {
		// Catches intentional <ENDOFFILE>
    	if errobj.Name'="<ENDOFFILE>",logging {
	    	u stdout WRITE "In Catch block Import Source File",!
			u stdout WRITE "  Error Name:",errobj.Name,!
    		u stdout WRITE "  Error code: ",errobj.Code,!
    		u stdout WRITE "  Error location: ",errobj.Location,!
    		u stdout WRITE "  Error data:",errobj.Data	
    	} else {
	    	/// Expected to hit EOF error
    	}
	}
	Close:device'=0 device
	u stdout Write !,"End Import Source File"
	Quit tSC
]]></Implementation>
</Method>

<Method name="WithTrailingPathSeperator">
<Description>
Adds trailing directory path seperator to directory path if needed</Description>
<ClassMethod>1</ClassMethod>
<CodeMode>expression</CodeMode>
<FormalSpec>directory</FormalSpec>
<Implementation><![CDATA[$Select($Extract(directory,*)?1(1"/",1"\"):directory,1:directory_$Select($SYSTEM.Version.GetBuildOS()="UNIX":"/",1:"\"))
]]></Implementation>
</Method>

<Method name="PurgeSigSource">
<Description>
Operates on Historic data
Leave Current Data intact</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>retainVersionCount=0,debug=0</FormalSpec>
<Implementation><![CDATA[
	Quit:retainVersionCount<0
	
	// Itterates over any history for an environment
	set dateOfData=""
	for {
		set dateOfData=$Order(^ompare("History",dateOfData),-1)
		quit:dateOfData=""
		
		set environment=""
		for {
			set environment=$Order(^ompare("History",dateOfData,environment))
			quit:environment=""
			
			continue:($Increment(retain(environment)))<=retainVersionCount
			
			W:debug !,"Purge Historic Data for Envrionment ",environment," for date ",$ZD(dateOfData)
			Kill ^ompare("History",dateOfData,environment)		
		}
	}
	
	// Truncate Src data that is orphaned
	Kill ^||DataSig
	
	// Itterate over each Current Signature leaf node
	set node="^ompare(""Data"")"
	for {
		set node=$Query(@node)
		quit:node=""  // end of history global
		quit:$E(node,1,30)'="^ompare(""Data"","
		continue:$L(@node)'=28  // Must be SHA1 Signature in Base64 encoding
		set ^||DataSig(@node)=""	
	}
	
	
	// Itterate over each Historic Signature leaf node
	// Note each node that is a signature
	set node="^ompare(""History"")"
	for {
		set node=$Query(@node)
		quit:node=""  // end of history global
		quit:$E(node,1,33)'="^ompare(""History"","
		continue:$L(@node)'=28  // Must be SHA1 Signature in Base64 encoding
		set ^||DataSig(@node)=""	
	}
	
	set sig=""
	for {
		set sig=$Order(^ompare("DataSrc",sig))
		quit:sig=""
		// Truncate unreportable obsolete Source
		 
		if $Data(^||DataSig(sig))=0 {
			W:debug !,"Purge Obsolete Source ",sig
			kill ^ompare("DataSrc",sig)
		}
	}
]]></Implementation>
</Method>

<Method name="GenerateBackupSourceCode">
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace=$NAMESPACE,exportDirectory="",environment=""</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	Quit:$L(exportDirectory)<3 $$$ERROR(5001,"ExportDirectory invalid")
	Quit:'##class(%File).DirectoryExists(exportDirectory) $$$ERROR(5001,"ExportDirectory does not exist")
	Quit:environment="" $$$ERROR(5001,"Logical environment parameter empty")
	
	set ret=$$$OK
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
	
	set currentIO=$IO
	set qspec="/mapped=0/diffexport=1/exportgenerated=0/system=0/percent=0"
	//----------------
	// Export ALL to get full export list
	set file=##class(%IO.NullStream).%New()
	s dev=exportDirectory_"PreExportList"_$ZSTRIP(environment,"*W")_".txt"
	o dev:"NWS":2
	quit:'$T $$$ERROR(5001,"Unable to open ExportList Directory")
	u dev s tSC=$SYSTEM.OBJ.ExportToStream(..#ExportItemTypes,.file,qspec,.errorlog)
	c dev
	
	s file=##class(%File).%New(dev)
	d file.Open("RS")
	if 'file.AtEnd {
		for {
			set line=file.Read(32000)
			Quit:file.AtEnd
			
			if line?1"Exporting class: "1.E {
				set name=$P(line," ",3)
				if '$$IsExcluded(name_".cls") set items(name_".cls")=""
			} elseif line?1"Exporting routine: "1.E {
				// Exporting routine: TRAK.inc
				// Exporting routine: CLNNHSW03.mac
				set name=$P(line," ",3)
				if '$$IsExcluded(name) set items(name)=""
			} elseif line?1"Exporting type : "1.E {
				// HL7
				// Exporting type : 2.5.1.HL7
				// ASTM	
				// Exporting type : E1394.AST
				// RUL
				//Exporting type : Interfaces.Rules.RouteMsgFromTCL.rul
				set name=$P(line," ",4)
				if '$$IsExcluded(name) set items(name)=""
			} else {
				// Ignore the line
				// Exporting CSP/CSR or file: 
			}
		}
	}
	do file.%Close()
	//----------------
	Quit:'$Data(items) $$$ERROR(5001,"Nothing included for backup export")
	
	// Backup Any Defined Ensemble Lookups
	// ie: In Ensemble 2010 these are not managed as Studio "LUT" files.
	set lookupKey=""
	for {
		set lookupKey=$Order(^Ens.lookupTable(lookupKey))
		quit:lookupKey=""
		set:'$$IsExcluded(lookupKey_".lut") items("Ens.lookupTable("""_lookupKey_""").GBL")=""
	}
	
	Set stream=##class(%File).%New(exportDirectory_"BU_"_environment_"_"_$NAMESPACE_"_"_$TR($ZDT($H,3)," -:")_".gz")
	set tSC=stream.Open("NWS:/GZIP=9",2)
	Quit:$$$ISERR(tSC)
	
	set ret=$SYSTEM.OBJ.ExportToStream(.items,.stream,qspec,.errorlog)
	if $$$ISOK(ret) {
		Do stream.Flush()
	}
	Do stream.Close()
	
	Quit ret
IsExcluded(name)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Explict match for exlcusion
	Quit:+$G(^Ens.LookupTable("ompare.Exclude",name_"."_extension)) 1
	// now recursively look to exclude by wildcard match.
	set found=0
	
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^Ens.LookupTable("ompare.Exclude",prefix_"."_extension))
		quit:found
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
]]></Implementation>
</Method>

<Method name="IsExcluded">
<ClassMethod>1</ClassMethod>
<FormalSpec>name=""</FormalSpec>
<Implementation><![CDATA[
	Quit:name="" 1
	Quit:+$G(^Ens.LookupTable("ompare.Exclude",name)) 1
	// now recursively look to match by wildcard.
	set found=0
	set extension=$P(name,".",$L(name,"."))
	set prefix=$e(name,1,*-($L(extension)+1))_"*"
	for {
		set found=+$G(^Ens.LookupTable("ompare.Exclude",prefix_"."_extension))
		quit:found
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
]]></Implementation>
</Method>

<Method name="PurgeProfileData">
<Description>
Caution - When run on a Reporting Server this would
Also clear Signature data collected from other systems</Description>
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[
	Kill ^ompare("DataSrc")
	Kill ^ompare("Data")
	Kill ^ompare("History")
]]></Implementation>
</Method>

<Method name="DebugLine">
<Description>
Convenience method to output debug information to the console
in programmer mode OR the Task Schedule Log file if set</Description>
<FormalSpec>message</FormalSpec>
<Implementation><![CDATA[
	quit:'..Debug
	set:..STDOUT="" ..STDOUT=$IO
	USE ..STDOUT WRITE message,!
]]></Implementation>
</Method>

<Method name="TODO">
<ClassMethod>1</ClassMethod>
<Implementation><![CDATA[	W !,$I(item),":SQLTable source encoding characters review"
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Base">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Base class Template for SourceHandler implementations.<br/>
This class would be of interest for persons who wish to implement additional
differencing functionality for other document types or environment parameters
not already provided by the ompare package.<br/>
Builds highlevel Signatures of implementation and <em>optionally</em> captures functional Source code.<br/>
The job of a SourceHander is to analyse code or environment configuration or state
and generate data that an be exported to flat file. Later these files can be 
transferred to a reporting service thus allowing comparison of disconnected systems.
SourceHandlers like Schedule are imported only into one namespace on a client server.
Only these <em>client</em> components of ompare package are needed to generate signature 
information.
The schedule detects sub-classes of the base class and will attempt to run them
where imported to the run namespace.
To exclude particular SourceHandlers, simply do not load them into the target run namespace.
The use of "Sub-Classing" Base allows the schedule to <em>Discover</em> and <em>Run</em> new Source Handler implementations added to a system.<br/>
The implementation pattern with line labels within the IndexNamespace Method is necessary in order
to retain functionality when switching namespace during execution.
See other SourceHandler implementation for examples defining macros
<ul><li>RPTType</li>
<li>RPTSubType___</li>
<li>RPTItemConfig___</li>
</ul>
Take care to define unique Type and SubType values across existing SourceHandlers.<br/>
The task of a SourceHandler is to build up ^||Data and ^||DataSrc process private gloabls
to represent source implmentation signatures and optionally extract source code sections.
LineLable <em>SetSignature</em> generates ^||Data entries for highlevel reporting
Optionally Line labels <em>AddLine</em> and <em>SaveLines</em> generate ^||DataSrc
for detailed difference reporting when appropriate.<br/>
Line label <em>IsExcluded</em> provides support exclusions for one or more source code
items for example classname or routinename.
Suggest use exclusions in the most permissible case to capture all possible areas
needed for reporting.
Subsequently reports can be defined that are configured to give different slices 
and or filtered views of analysed code.
Exclude configuration leverages entries in ensemble lookuptable "ompare.Exclude" where
<example>
^ompare("Config","Exclude",key_".extension")=value
</example>
To exclude System classes by package prefix
<example>
^ompare("Config","Exclude","%*.cls")=0
</example>
To include user class by full classname:
<example>
^ompare("Config","Exclude","ompare.SourceHandler.Base.cls")=1
</example>
Value is either "1" (include for processing), "0" (don't include for processing)
Rationale. 
<ol><li>Reuse existing SMP page to create, and edit lookup table.</li>
<li>Each namespace has an independent configuration for how the SourceHandler should 
include source items</li></ol>
Exclusions can layer for example to exclude all classes within package "ompare"
except do include analysis of the SourceHandler subpackage:
<example>
^ompare("Config","Exclude","ompare.*.cls")=1
^ompare("Config","Exclude","ompare.SourceHandler.*.cls")=0
</example>
SourceHandlers implemented in ompare package will add default exclusion entries
to namespaces when run for a first time, where no existing entries are found
for a given document type for example: "*.cls" or "*.mac"]]></Description>
<Abstract>1</Abstract>
<IncludeCode>%occInclude</IncludeCode>
<TimeChanged>66487,51835</TimeChanged>
<TimeCreated>64075,59101.512729</TimeCreated>

<Parameter name="InvokePerNamespace">
<Description><![CDATA[
When Invoke per namespace is "0"
the Index method will be called once only.<br/>
When InvokePerNamespace is "1"
the Index method will be called for each Namespace that is managed</br>]]></Description>
<Default>1</Default>
</Parameter>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
</Parameter>

<Method name="IndexNamespace">
<Description>
Do not invoke supporting methods on this class definition</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "?"
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	if '..#InvokePerNamespace {
		Quit:namespace=""
	
		New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
		try {	
			 // Generates <NAMESPACE> error if namespace doesn't exist
			 // Generate <PROTECT> error if user does not have access privilage
			set $NAMESPACE=namespace
		} catch errobj {
			// Name
			// Code
			// Location
			// Data
			if errobj.Name="<NAMESPACE>" {
				set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
			} elseif errobj.Name="" {
				set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
			} else {
				set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
			}
		}
		Quit:$$$ISERR(ret) ret
	}
	
	// Invoke sub-class extension code
	Do IndexerMain
	
	Quit ret
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  // Intercept Source Control Tokens
  // eg: $I + d: //some/org/project/product/BASE/rtn/PRTDR9ORG.rtn#1 $
  // Converts to $I + d$
  set dataNoTokenVersion=""
  if schedule.SrcVersionTokenStart'="" {
	if schedule.SrcVersionTokenEnd'="" {
		set pattern=".E1"""_schedule.SrcVersionTokenStart_"""1.E1"""_schedule.SrcVersionTokenEnd_""""
  		for {
		  quit:data'?@pattern
		  s dataNoTokenVersion=dataNoTokenVersion_$P(data,schedule.SrcVersionTokenStart)_schedule.SrcVersionTokenStart_schedule.SrcVersionTokenEnd
		  set data=$P($P(data,schedule.SrcVersionTokenStart,2,999999),schedule.SrcVersionTokenEnd,2,999999)
	  	}
	} elseif data[schedule.SrcVersionTokenStart {
		// The source control token effectively matches to the end of the line
		set data=$P(data,schedule.SrcVersionTokenStart)	
	}
  }
  // Include remainder of line after token end if token version content removed
  set:$L(dataNoTokenVersion)>0 data=dataNoTokenVersion_data
  Do tmpStream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value)
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/
	
	//Do Log("Start",$ZDT($H,3))
	//Do SetSignature("Class1","sig")
	//Do SetSignature("Class1","sig","PROP","TESTPROP")
	//Do Log("End",$ZDT($H,3))
	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Class">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Source Analyser for Class Definitions.
Extracts:
<ol><li>Implemention signatures for highlevel diffs for Parameters, Properties, Method Signature, Method Body, XData and Class Summary.</li>
<li><em>Optionally</em> Functional source code lines for full-diff reporting of Parameters, Properties, Method Signature, Method Body, XData and Class Summary.</li>
<li>Creates an summary signature of Class independent of the order in which Parameters, Methods, XData are defined</li>
</ol>
Source line leading and trailing whitespace is normalised.<br/>
To exclude source code from being captured for detailed reports use schedule configuration
option IncludeSourceCode=0<br/>
To control which packages are included in each target namespace for analysis 
update the lookup global using Interoperability LookupTables in SMP or directly.
When first run in each namespace the following default will be established:
<example>
^ompare("Config","Exclude","%*.cls")=1
^ompare("Config","Exclude","Ens.*.cls")=1
^ompare("Config","Exclude","EnsPortal.*.cls")=1
^ompare("Config","Exclude","EnsLib.*.cls")=1
^ompare("Config","Exclude","CSPX.*.cls")=1
^ompare("Config","Exclude","INFORMATION.*.cls")=1
^ompare("Config","Exclude","HS.*.cls")=1
^ompare("Config","Exclude","HSMOD.*.cls")=1
</example>
Where value "1" means exclude and "0" means include
Exclusions can layer for example to exclude all classes within package "ompare"
except do include analysis of the SourceHandler subpackage:
<example>
^ompare("Config","Exclude","ompare.*.cls")=1
^ompare("Config","Exclude","ompare.SourceHandler.*.cls")=0
</example>]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51845</TimeChanged>
<TimeCreated>64118,38047.434169</TimeCreated>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>C</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Main entry point for Class Definition Source Handler
Do ##class(ompare.SourceHandler.Class).IndexNamespace($namespace,1)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if '$IsObject(schedule) {
		set schedule=##class(ompare.Schedule).%New()
		// Uses defaults
	}
#define RPTType "C"
#define RPTSubTypeConfig "CFG"
#define RPTItemConfigMapped "IsMapped"
#define RPTItemConfigSourceControlled "IsSourceControlled"
#define RPTItemConfigSourceVersion "SrcVer"
#define RPTSubTypeSummary "S"
#define RPTSubTypeProperty "P"
#define RPTSubTypeParameter "PR"
#define RPTSubTypeMethod "M"
#define RPTSubTypeMethodSignature "MS"
#define RPTSubTypeXData "X"
 // Persistent Storage
#define RPTSubTypeStorage "ST" 

 // Testing
 // Do ##class(ompare.SourceHandler.ClassDefinition).IndexNamespace("INTEG-MARS",0,0)

	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	/*****************************
	 Start Template
	******************************/
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
		Quit:namespace=""
	
		New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
		try {	
			 // Generates <NAMESPACE> error if namespace doesn't exist
			 // Generate <PROTECT> error if user does not have access privilage
			set $NAMESPACE=namespace
		} catch errobj {
			// Name
			// Code
			// Location
			// Data
			if errobj.Name="<NAMESPACE>" {
				set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
			} elseif errobj.Name="" {
				set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
			} else {
				set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
			}
		}
		Quit:$$$ISERR(ret) ret
	
	try {
		// Invoke sub-class extension code
		Do IndexerMain  //(logging, includeSource)
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.ClassDefinition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	
	Quit ret
SetIsMapped(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:'##class(%Dictionary.CompiledMethod).%ExistsId("%Studio.SourceControl.ISC||IsMapped")
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigMapped)=##class(%Studio.SourceControl.ISC).IsMapped(typeName_".CLS")
	quit
SetIsSourceControlled(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:$Data(^Sources)<11
	quit:$$SourceControlClass^%occLibrary($Namespace)'="%Studio.SourceControl.ISC"
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceControlled)=##class(%File).Exists(##class(%Studio.SourceControl.ISC).ExtName(typeName_".CLS"))
	quit
SetSourceVersion(classname)
	quit:$$$RPTType=""
	quit:classname=""
	quit:'$IsObject(schedule)
	
	set obj=##class(%Dictionary.CompiledParameter).%OpenId(classname_"||"_schedule.SrcVersionParameter,0)
	if '$IsObject(obj) Do:logging Log("SrcVer no object",classname_"||"_schedule.SrcVersionParameter)
	Quit:'$IsObject(obj)
	set data=$ZSTRIP(obj.Default,"<>W")
	set:$E(data,1)=":" data=$ZSTRIP($E(data,2,*),"<>W")
	if data="" Do:logging Log("SrcVer no default",classname_"||SrcVer")
	quit:data=""
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,classname,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceVersion)=data
	quit
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc

WriteLine(stream,data)
  // Intercept Source Control Tokens
  // eg: $I + d: //some/org/project/product/BASE/rtn/PRTDR9ORG.rtn#1 $
  // Converts to $I + d$
  set dataNoTokenVersion=""
  if schedule.SrcVersionTokenStart'="" {
	if schedule.SrcVersionTokenEnd'="" {
		set pattern=".E1"""_schedule.SrcVersionTokenStart_"""1.E1"""_schedule.SrcVersionTokenEnd_""""
  		for {
		  quit:data'?@pattern
		  s dataNoTokenVersion=dataNoTokenVersion_$P(data,schedule.SrcVersionTokenStart)_schedule.SrcVersionTokenStart_schedule.SrcVersionTokenEnd
		  set data=$P($P(data,schedule.SrcVersionTokenStart,2,999999),schedule.SrcVersionTokenEnd,2,999999)
	  	}
	} elseif data[schedule.SrcVersionTokenStart {
		// The source control token effectively matches to the end of the line
		set data=$P(data,schedule.SrcVersionTokenStart)	
	}
  }
  // Include remainder of line after token end if token version content removed
  set:$L(dataNoTokenVersion)>0 data=dataNoTokenVersion_data
  Do tmpStream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value="")
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
	
IndexerMain  //(logging, includeSource)
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/
	
	// No need to delete class information from previous processing
	// as output will REPLACE previous information on signatures
	
	
	// Default exclusions in this namespace
	// Start set once in first run namespace
	set hasClassConfig=0
	set testExclude=""
	for {
		set testExclude=$O(^ompare("Config","Exclude",testExclude))
		quit:testExclude=""
		if $E(testExclude,*-3,*)=".cls" {
			set hasClassConfig=1
			quit  // exit on first encountered
		}
	}
	if 'hasClassConfig {
		set ^ompare("Config","Exclude","%*.cls")=1
		set ^ompare("Config","Exclude","Ens.*.cls")=1
		set ^ompare("Config","Exclude","EnsPortal.*.cls")=1
		set ^ompare("Config","Exclude","EnsLib.*.cls")=1
		set ^ompare("Config","Exclude","CSPX.*.cls")=1
		set ^ompare("Config","Exclude","INFORMATION.*.cls")=1
		set ^ompare("Config","Exclude","HS.*.cls")=1
		set ^ompare("Config","Exclude","HSMOD.*.cls")=1
	}
	// End set once in first run namespace
	
	s rs=##class(%ResultSet).%New()
	set rs.ClassName="%Dictionary.ClassDefinition"
	set rs.QueryName="ClassIndex"
	do rs.Execute()
	for {
		quit:'rs.Next()
		set classname=rs.Data("ClassName")
		Do:logging Log("Found classname",classname)
		
		// Ignorning classes marked "system" is not reliable
		// excludes some application classes needed
		//if (rs.Data("System")>0) {
		//	// ignore system classes
		//	Do:logging Log("Ignore System",rs.Data("System"))
		//	continue
		if (rs.Data("Generated")>0) {
			// "csp.*" is a reserved prefix for generated Classes from CSP pages
			// Due to issue detecting differences in compiled classes after refresh,
			// we leave in a profile of Classes from CSP pages
			// in order to detect compiled differences between environments
			if classname'?1"csp.".E {
		    	// ignore generated classes
		    	Do:logging Log("Ignore Generated",rs.Data("Generated"))
		    	continue
			}
		}
		
		if $$IsExcluded(classname_".cls",.reason) {
			Do:logging Log("Ignore """_classname_""" matches filter",reason)
			continue	
		}
		Do:logging Log("IndexClass",classname_tmpStream)
		Do IndexClass(classname,tmpStream) //,includeSource)
	}
	do rs.Close()
	Quit
IndexClass(classname,tmpStream) //,includeSource)
	Quit:classname=""
	Quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	
	set classobj=##class(%Dictionary.ClassDefinition).%OpenId(classname,0)
	quit:'$IsObject(classobj)
	set deployed=classobj.Deployed
	
	// Class Summary
	#dim stream as %Stream.TmpCharacter
	set line=0
	
	Do WriteLine(tmpStream,"Abstract:"_classobj.Abstract)
	Do WriteLine(tmpStream,"ClassType:"_classobj.ClassType)
	Do WriteLine(tmpStream,"ClientDataType:"_classobj.ClientDataType)
	Do WriteLine(tmpStream,"ClientName:"_classobj.ClientName)
	Do WriteLine(tmpStream,"CompileAfter:"_classobj.CompileAfter)
	Do WriteLine(tmpStream,"ConstrainClass:"_classobj.ConstraintClass)
	Do WriteLine(tmpStream,"DdlAllowed:"_classobj.DdlAllowed)
	Do WriteLine(tmpStream,"DependsOn:"_classobj.DependsOn)
	Do WriteLine(tmpStream,"Final:"_classobj.Final)
	Do WriteLine(tmpStream,"Hidden:"_classobj.Hidden)
	Do WriteLine(tmpStream,"Import:"_classobj.Import)
	Do WriteLine(tmpStream,"IncludeCode:"_classobj.IncludeCode)
	Do WriteLine(tmpStream,"IncludeGenerator:"_classobj.IncludeGenerator)
	Do WriteLine(tmpStream,"IndexClass:"_classobj.IndexClass)
	Do WriteLine(tmpStream,"Inheritance:"_classobj.Inheritance)
	// Ensure same output as for IRIS
	if classobj.Language="cache" {
		Do WriteLine(tmpStream,"Language:objectscript")
	} else {
		Do WriteLine(tmpStream,"Language:"_classobj.Language)
	}
	Do WriteLine(tmpStream,"MemberSuper:"_classobj.MemberSuper)
	Do WriteLine(tmpStream,"NoExtent:"_classobj.NoExtent)
	Do WriteLine(tmpStream,"OdbcType:"_classobj.OdbcType)
	Do WriteLine(tmpStream,"ProcedureBlock:"_classobj.ProcedureBlock)
	Do WriteLine(tmpStream,"ProjectionClass:"_classobj.ProjectionClass)
	Do WriteLine(tmpStream,"PropertyClass:"_classobj.PropertyClass)
	Do WriteLine(tmpStream,"QueryClass:"_classobj.QueryClass)
	Do WriteLine(tmpStream,"ServerOnly:"_classobj.ServerOnly)
	Do WriteLine(tmpStream,"SoapBindingStyle:"_classobj.SoapBindingStyle)
	Do WriteLine(tmpStream,"SoapBodyUse:"_classobj.SoapBodyUse)
	Do WriteLine(tmpStream,"SqlCategory:"_classobj.SqlCategory)
	Do WriteLine(tmpStream,"SqlRowIdName:"_classobj.SqlRowIdName)
	Do WriteLine(tmpStream,"SqlRowIdPrivate:"_classobj.SqlRowIdPrivate)
	Do WriteLine(tmpStream,"SqlTableName:"_classobj.SqlTableName)
	Do WriteLine(tmpStream,"StorageStratergy:"_classobj.StorageStrategy)
	Do WriteLine(tmpStream,"Super:"_classobj.Super)
	Do WriteLine(tmpStream,"ViewQuery:"_classobj.ViewQuery)
	
	set classobj=""
	
	set obj=""
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeSummary,"Summary")
	Do:includeSource SaveLines(sig)
	
	// End Class Summary
	
	// Get all the parameters associated with this class definition
	set rsProp=##class(%ResultSet).%New()
	set rsProp.ClassName="%Dictionary.ParameterDefinition"  // %Dictionary.CompiledParameter
	set rsProp.QueryName="Summary"
	set tSC=rsProp.Execute(classname)
	if $$$ISOK(tSC) {
		for {
			Quit:'rsProp.Next()
			// Ignore Perforce Parameter "SrcVer"
			continue:rsProp.Data("Name")="SrcVer"
			
			// Special processing for classes generated from CSP pages
			if classname?1"csp.".E {
				// Parameters to always / maybe different between environments
				continue:rsProp.Data("Name")?1(1"CSPFILE",1"CSPURL",1"FileTimestamp")
			}
			
			do IndexParameter(rsProp.Data("Name"),tmpStream)
		}
	}
	do rsProp.Close()
	
	
	// Get all properties associated with this class definition
	set rsProp=##class(%ResultSet).%New()
	set rsProp.ClassName="%Dictionary.PropertyDefinition"
	set rsProp.QueryName="Summary"
	set tSC=rsProp.Execute(classname)
	if $$$ISOK(tSC) {
		for {
			Quit:'rsProp.Next()
			do IndexProperty(rsProp.Data("Name"),tmpStream)
		}
	}
	do rsProp.Close()

	// Get all methods associated with this classdefinition
	set rsMeth=##class(%ResultSet).%New()
	set rsMeth.ClassName="%Dictionary.MethodDefinition"
	set rsMeth.QueryName="Summary"
	set tSC=rsMeth.Execute(classname)
	if $$$ISOK(tSC) {
		for {
			Quit:'rsMeth.Next()
			Do tmpStream.Clear()
			do IndexMethod(rsMeth.Data("Name"),tmpStream,deployed) //,includeSource)
			Do tmpStream.Clear()
			do IndexMethodSig(rsMeth.Data("Name"),tmpStream,deployed)
		}
	}
	do rsMeth.Close()
		
	if 'deployed {
		//XData processing. Eg: For Ensemble Transforms
		set rsXData=##class(%ResultSet).%New()
		set rsXData.ClassName="%Dictionary.XDataDefinition"
		set rsXData.QueryName="Summary"
		set tSC=rsXData.Execute(classname)
		if $$$ISOK(tSC) {
			for {
				Quit:'rsXData.Next()
				Do tmpStream.Clear()
				do IndexXData(rsXData.Data("Name"),tmpStream) //,includeSource)
			}
		}
		do rsXData.Close()
	}

	do IndexStorage(classname,tmpStream)

	set classSummary=classname
	// After completing detail for line labels make a signature for the whole routine
	// Note that the order of the line labels is not functionally important
	set classSuper=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeSummary,.classSuper)
		set classSummary=classSummary_";"_classSuper_":"_sig
	}
	set currentParameter=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeParameter,.currentParameter)
		set classSummary=classSummary_";"_currentParameter_":"_sig
	}	
	set currentProperty=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeProperty,.currentProperty)
		set classSummary=classSummary_";"_currentProperty_":"_sig
	}
	set currentMethodSig=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeMethodSignature,.currentMethodSig)
		set classSummary=classSummary_";"_currentMethodSig_":"_sig	
	}
	set currentMethod=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeMethod,.currentMethod)
		set classSummary=classSummary_";"_currentMethod_":"_sig	
	}
	set currentXData=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeXData,.currentXData)
		set classSummary=classSummary_";"_currentXData_":"_sig	
	}
	set currentStorage=""
	for {
		Quit:'$$NextSignature(classname,.sig,$$$RPTSubTypeStorage,.currentStorage)
		set classSummary=classSummary_";"_currentStorage_":"_sig
	}
	
	Do SetSignature(classname, $SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1Hash(classSummary)))
	Do SetIsMapped(classname)
	Do SetIsSourceControlled(classname)
	Do SetSourceVersion(classname)
	Quit
IndexParameter(parametername="",tmpStream="")
	quit:parametername=""
	Quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	set obj=##class(%Dictionary.ParameterDefinition).%OpenId(classname_"||"_parametername,0)
	//set obj=##class(%Dictionary.CompiledParameter).%OpenId(classname_"||"_parametername,0)
	Quit:'$IsObject(obj)
	set line=0
	Do WriteLine(tmpStream,"Abstract:"_obj.Abstract)
	Do WriteLine(tmpStream,"Default:"_obj.Default)
	Do WriteLine(tmpStream,"Final:"_obj.Final)
	Do WriteLine(tmpStream,"Flags:"_obj.Flags)
	// Not interested in Sequence

	set obj=""
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeParameter,parametername)
	Do:includeSource SaveLines(sig)
	Quit
IndexProperty(propertyname="",tmpStream="")
	Quit:propertyname=""
	Quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	#dim stream as %Stream.TmpCharacter
	
	set line=0
	
	//Do ##class(ompare.Report.Template).IndexProperty("BASE","TRAKLAB","ompare.Report.Template","ReportName")
	
	// Open the property (NO CONCURRENCY) and get the specification
	s obj=##class(%Dictionary.PropertyDefinition).%OpenId(classname_"||"_propertyname,0)
	Quit:'$IsObject(obj)
	
	Do WriteLine(tmpStream,"Calculated:"_obj.Calculated)
	Do WriteLine(tmpStream,"Cardinality:"_obj.Cardinality)
	Do WriteLine(tmpStream,"ClientName:"_obj.ClientName)
	Do WriteLine(tmpStream,"Collection:"_obj.Collection)
	Do WriteLine(tmpStream,"Final:"_obj.Final)
	Do WriteLine(tmpStream,"Identity:"_obj.Identity)
	Do WriteLine(tmpStream,"InitialExpression:"_obj.InitialExpression)
	Do WriteLine(tmpStream,"Internal:"_obj.Internal)
	Do WriteLine(tmpStream,"Inverse:"_obj.Inverse)
	Do WriteLine(tmpStream,"MultiDimensional:"_obj.MultiDimensional)
	Do WriteLine(tmpStream,"Parameters:")
	s key=""
	for {
		set value=obj.Parameters.GetNext(.key)
		quit:key=""
		Do WriteLine(tmpStream,"  "_key_"="_value)
	}
	Do WriteLine(tmpStream,"Private:"_obj.Private)
	Do WriteLine(tmpStream,"ReadOnly:"_obj.ReadOnly)
	Do WriteLine(tmpStream,"Relationship:"_obj.Relationship)
	Do WriteLine(tmpStream,"Required:"_obj.Required)
	// Not interested in SequenceNumber
	Do WriteLine(tmpStream,"ServerOnly:"_obj.ServerOnly)
	Do WriteLine(tmpStream,"SqlColumnNumber:"_obj.SqlColumnNumber)
	Do WriteLine(tmpStream,"SqlComputeCode:"_obj.SqlComputeCode)
	Do WriteLine(tmpStream,"SqlComputeOnChange:"_obj.SqlComputeOnChange)
	Do WriteLine(tmpStream,"SqlComputed:"_obj.SqlComputed)
	Do WriteLine(tmpStream,"SqlFieldName:"_obj.SqlFieldName)
	Do WriteLine(tmpStream,"SqlListDelimiter:"_obj.SqlListDelimiter)
	Do WriteLine(tmpStream,"SqlListType:"_obj.SqlListType)
	Do WriteLine(tmpStream,"Transient:"_obj.Transient)
	Do WriteLine(tmpStream,"Type:"_obj.Type)
	
	set obj=""
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeProperty,propertyname)
	Do:includeSource SaveLines(sig)
	
	Quit
	// This line label is now only interested in the source implementation
	// See IndexMethodSig for method paramater configuration
IndexMethod(methodname="",tmpStream,deployed) //,includeSource)
	quit:methodname=""
	Quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	s obj=##class(%Dictionary.MethodDefinition).%OpenId(classname_"||"_methodname,0)
	Quit:'$IsObject(obj)
	
	set line=0
	
	//Do tmpStream.WriteLine(methodname)
	#dim stream as %Stream.TmpCharacter
	if deployed {
		Do WriteLine(tmpStream,"Implementation:Deployed")
	} else {	
		
		s stream=obj.Implementation
		if $IsObject(stream) {
			//Do tmpStream.WriteLine("Implementation:")
			do stream.Rewind()
			set inmultilinecomment=0
			for {
				quit:stream.AtEnd
				set data=$ZSTRIP(stream.ReadLine(32000),">W")
				continue:data=""
				
				// Remove multiline comments from signatures
				if inmultilinecomment=0,$L(data,"/*")>1 {
					if $L(data,"*/")=1 {
						// No end comment
						set inmultilinecomment=1
						set data=$P(data,"/*")  // Throw away the comment information
					} else {
						set data=$P(data,"/*")_$P(data,"*/",2) // Throw away the comment section
					}
				} elseif inmultilinecomment {
					if $L(data,"*/")=1 {
						continue  // still in the multi-line comment	
					} else {
						set inmultilinecomment=0
						// Allow code after comment end to be processed
						// Prefix with space as this is not a line label within a method
						set data=" "_$P(data,"*/",2)  
					}
				}
				// If line is not a line label
				if $E(data,1)'?1(1A,1"%") {
					// Discard leading whitespace that is simply followed by comments
					// Discard leading dot syntax that is simply followed by comments
					set tmpdata1=$ZSTRIP($TR(data,"."),"<W")
					if tmpdata1="" {
						continue
					}
					if $E(tmpdata1,1)=";" {
						continue
					}
					if $E(tmpdata1,1,2)="//" {
						continue
					}
				}
				// TODO - Question regarding lines with leading TABS $C(9) not being added to source code for signature?
				Do WriteLine(.tmpStream,.data)
			}
		} else {

		}
	}
	set obj=""
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeMethod,methodname)
	Do:includeSource SaveLines(sig)
	
	w:logging !,!,!,"******************************"
	// Logging
	Do:logging tmpStream.Rewind()
	Do:logging tmpStream.OutputToDevice()
	W:logging !,"******************************",!,!,!
	
	Do tmpStream.Clear()
	Quit
IndexMethodSig(methodname="",tmpStream,deployed)
	quit:methodname=""
	quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	set obj=##class(%Dictionary.MethodDefinition).%OpenId(classname_"||"_methodname,0)
	quit:'$IsObject(obj)
	
	set line=0
	
	// Do tmpStream.WriteLine(methodname)
	Do WriteLine(tmpStream,"Abstract:"_obj.Abstract)
	Do WriteLine(tmpStream,"ClassMethod:"_obj.ClassMethod)
	Do WriteLine(tmpStream,"ClientMethod:"_obj.ClientMethod)
	Do WriteLine(tmpStream,"ClientName:"_obj.ClientName)
	Do WriteLine(tmpStream,"CodeMode:"_obj.CodeMode)
	Do WriteLine(tmpStream,"ExternalProcName:"_obj.ExternalProcName)
	Do WriteLine(tmpStream,"Final:"_obj.Final)
	Do WriteLine(tmpStream,"ForceGenerate:"_obj.ForceGenerate)
	Do WriteLine(tmpStream,"FormalSpec:"_obj.FormalSpec)  // List of arguements in format [&|*]<name>[:<type>][=<default>]
	Do WriteLine(tmpStream,"GenerateAfter:"_obj.GenerateAfter)
	Do WriteLine(tmpStream,"Internal:"_obj.Internal)
	if obj.Language="cache" {
		Do WriteLine(tmpStream,"Language:objectscript")
	} else {
		Do WriteLine(tmpStream,"Language:"_obj.Language)
	}
	Do WriteLine(tmpStream,"NoContext:"_obj.NoContext)
	Do WriteLine(tmpStream,"NotInheritable:"_obj.NotInheritable)
	Do WriteLine(tmpStream,"PlaceAfter:"_obj.PlaceAfter)
	Do WriteLine(tmpStream,"ProcedureBlock:"_obj.ProcedureBlock)
	Do WriteLine(tmpStream,"PublicList:"_obj.PublicList)
	Do WriteLine(tmpStream,"ReturnResultsets:"_obj.ReturnResultsets)
	Do WriteLine(tmpStream,"ReturnType:"_obj.ReturnType)
	// A comma separated list of any parameters on the ReturnType keyword
	Do WriteLine(tmpStream,"ReturnTypeParams:"_obj.ReturnTypeParams)
	// Do tmpStream.WriteLine("SequenceNumber:"_obj.SequenceNumber)  Not interested in sequence
	// Removing Sequence number from criteria. Assuming this indicates the order for source code editing
	// which currently is not taken as functional difference with manual intergration of code
	if obj.SoapAction="[default]" {
		Do WriteLine(tmpStream,"SoapAction:")
	} else {
		Do WriteLine(tmpStream,"SoapAction:"_obj.SoapAction)
	}
	Do WriteLine(tmpStream,"SoapBindingStyle:"_obj.SoapBindingStyle)
	Do WriteLine(tmpStream,"SoapBodyUse :"_obj.SoapBodyUse)
	Do WriteLine(tmpStream,"SoapMessageName:"_obj.SoapMessageName)
	Do WriteLine(tmpStream,"SoapNameSpace:"_obj.SoapNameSpace)
	Do WriteLine(tmpStream,"SoapTypeNameSpace:"_obj.SoapTypeNameSpace)
	Do WriteLine(tmpStream,"SqlName:"_obj.SqlName)
	Do WriteLine(tmpStream,"SqlProc:"_obj.SqlProc)
	Do WriteLine(tmpStream,"WebMethod"_obj.WebMethod)
	Do WriteLine(tmpStream,"ZenMethod:"_obj.ZenMethod)
	set obj=""
		
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeMethodSignature,methodname)
	Do:includeSource SaveLines(sig)
	
	do tmpStream.Clear()
	quit
IndexXData(xdataname="",tmpStream) //,includeSource)
	quit:xdataname=""
	Quit:'$IsObject(tmpStream)
	Do tmpStream.Rewind()
	s obj=##class(%Dictionary.XDataDefinition).%OpenId(classname_"||"_xdataname,0)
	Quit:'$IsObject(obj)
	
	set line=0
	s stream=obj.Data
	if $IsObject(stream) {
		Do tmpStream.WriteLine("Data:IsObject")
		do stream.Rewind()
		for {
			quit:stream.AtEnd
			set data=$ZSTRIP(stream.ReadLine(32000),">W")
			continue:data=""
			
			// xdataname="DTL" WHERE class = Ens.DataTransformDTL
			// xdataname="BPL" WHERE class = Ens.BusinessProcess
			if ((xdataname="DTL")||(xdataname="BPL")),$E(data,1)'?1(1A,1"%") {

				// ignore lines of ". . ." do level nesting with no actual content
				// Discard leading dot syntax that is simply followed by comments
				set tmpdata1=$ZSTRIP($TR(data,"."),"<W")
				if tmpdata1="" {
					continue
				}
				
				// Discard leading whitespace that is simply followed by comments
				// Simple approach to manage comments in CDATA in <CODE> elements
				
				// Old COS style comments
				if $E(tmpdata1,1)=";" {
					continue
				}
				// New COS style comments
				if $E(tmpdata1,1,2)="//" {
					continue
				}
				
				// TODO Cater for "/* Comment */" style of comment
				// TODO Cater for <!- Comment ->
			}
			// TODO - Question regarding lines with leading TABS $C(9) not being added to source code for signature?
			Do WriteLine(tmpStream,data)
		}
	} else {
		Do tmpStream.WriteLine("Data:")
	}
	
	set obj=""
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(classname, sig,$$$RPTSubTypeXData,xdataname)
	Do:includeSource SaveLines(sig)
	
	if logging {
		W !,!,!,"******************************"
		// Logging
		Do tmpStream.Rewind()
		Do tmpStream.OutputToDevice()
		W !,"******************************",!,!,!
	}
	
	Do tmpStream.Clear()
	
	Quit
	// Suppresses:
	// * SequenceNumber - This seems to be different / higher between Cache 2010.2 and Cache 2015
	// * Properties()->Selectivity
	// * Properties()->ChildExtentSize
	// * ExtentSize
	// Depreciates:
	// * Origin - No longer used in Cache 2015+
IndexStorage(classname="",tmpStream) //,includeSource)
	quit:classname=""
	Quit:'$IsObject(tmpStream)
	
	#dim objSt as %Dictionary.StorageDefinition
	#dim dataSt as %Dictionary.StorageDataDefinition
	#dim indexSt as %Dictionary.StorageIndexDefinition
	#dim propertySt as %Dictionary.StoragePropertyDefinition
	#dim sqlmapSt as Dictionary.StorageSQLMapDefinition
	
	s rsSt=##class(%ResultSet).%New("%Dictionary.StorageDefinition:Summary")
	set tSC=rsSt.Execute(classname)
	quit:$$$ISERR(tSC)
	for {
		quit:'rsSt.Next()
		set storage=rsSt.Data("Name")
		quit:storage=""
	
		set objSt=##class(%Dictionary.StorageDefinition).%OpenId(classname_"||"_storage,0)
		quit:objSt=""
		
		// For each storage defintion, 1. Rewind Source Stream, 2. Reset Source Global to begining
		Do tmpStream.Rewind()
		set line=0
		
		//Do WriteLine(tmpStream,"CounterLocation:"_objSt.CounterLocation)
		Set def("CounterLocation")=objSt.CounterLocation
		//Do WriteLine(tmpStream,"Data:")
		
		kill def
		set key=""
		for {
			set dataSt=objSt.Data.GetNext(.key)	
			quit:key=""
			continue:'$IsObject(dataSt)
			//Do WriteLine(tmpStream,"  Name:"_dataSt.Name)
			set def("Data","Name:"_dataSt.Name)=""
			//Do WriteLine(tmpStream,"    Attribute:"_dataSt.Attribute)
			set def("Data","Name:"_dataSt.Name,"Attribute")=dataSt.Attribute
			//Do WriteLine(tmpStream,"    Structure:"_dataSt.Structure)
			set def("Data","Name:"_dataSt.Name,"Structure")=dataSt.Structure
			//Do WriteLine(tmpStream,"    Subscript:"_dataSt.Subscript)
			set def("Data","Name:"_dataSt.Name,"Subscript")=dataSt.Subscript
			//Do WriteLine(tmpStream,"    Values:")
			
			set keyValues=""
			for {
				set valueSt=dataSt.Values.GetNext(.keyValues)
				quit:keyValues=""
				continue:'$IsObject(valueSt)
				//Do WriteLine(tmpStream,"      Name:"_valueSt.Name)
				
				//Do WriteLine(tmpStream,"        Value:"_valueSt.Value)
				set def("Data","Name:"_dataSt.Name,"Values","Name:"_valueSt.Name,"Value")=valueSt.Value
			}
		}
		//Do WriteLine(tmpStream,"DataLocation:"_objSt.DataLocation)
		set def("DataLocation")=objSt.DataLocation
		//Do WriteLine(tmpStream,"DefaultData:"_objSt.DefaultData)
		set def("DefaultData")=objSt.DefaultData
		//Do WriteLine(tmpStream,"ExtentSize:"_objSt.ExtentSize)
		//set def("ExtentSize")=objSt.ExtentSize - Suppressed
		//Do WriteLine(tmpStream,"Final:"_objSt.Final)
		set def("Final")=objSt.Final
		//Do WriteLine(tmpStream,"IdExpression:"_objSt.IdExpression)
		set def("IdExpression")=objSt.IdExpression
		//Do WriteLine(tmpStream,"IdLocation:"_objSt.IdLocation)
		set def("IdLocation")=objSt.IdLocation
		//Do WriteLine(tmpStream,"IndexLocation:"_objSt.IndexLocation)
		set def("IndexLocation")=objSt.IndexLocation
		//Do WriteLine(tmpStream,"Indices:")  //%Dictionary.StorageIndexDefinition 
		set keyIndices=""
		for {
			set indexSt=objSt.Indices.GetNext(.keyIndices)
			quit:keyIndices=""
			continue:'$IsObject(indexSt)
			//Do WriteLine(tmpStream,"  Name:"_indexSt.Name)
			//Do WriteLine(tmpStream,"    Location:"_indexSt.Location)
			set def("Indices","Name:"_indexSt.Name,"Location")=indexSt.Location
		}
		//Do WriteLine(tmpStream,"Internal:"_objSt.Internal)
		set def("Internal")=objSt.Internal
		//Do WriteLine(tmpStream,"Name:"_objSt.Name)
		set def("Name")=objSt.Name
		//Do WriteLine(tmpStream,"Origin:"_objSt.Origin)
		//set def("Origin")=objSt.Origin  // Does not Exist on 2016!!
		//Do WriteLine(tmpStream,"Properties:") //%Dictionary.StoragePropertyDefinition
		set keyProperties=""
		for {
			set propertySt=objSt.Properties.GetNext(.keyProperties)
			quit:keyProperties=""
			continue:'$IsObject(propertySt)
			//Do WriteLine(tmpStream,"  Name:"_propertySt.Name)
			//Do WriteLine(tmpStream,"    ChildExtentSize:"_propertySt.ChildExtentSize)
			//set def("Properties","Name:"_propertySt.Name,"ChildExtentSize")=propertySt.ChildExtentSize - Suppressed
			//Do WriteLine(tmpStream,"    Selectivity:"_propertySt.Selectivity)
			//set def("Properties","Name:"_propertySt.Name,"Selectivity")=propertySt.Selectivity - Suppressed
			//Do WriteLine(tmpStream,"    StreamLocation:"_propertySt.StreamLocation)
			set def("Properties","Name:"_propertySt.Name,"StreamLocation")=propertySt.StreamLocation
		}
		
		//Do WriteLine(tmpStream,"SQLMaps :") // %Dictionary.StorageSQLMapDefinition
		set keySqlmaps=""
		for {
			set sqlmapSt=objSt.SQLMaps.GetNext(.keySqlmaps)
			quit:keySqlmaps=""
			continue:'$IsObject(sqlmapSt)
			//Do WriteLine(tmpStream,"  Name:"_sqlmapSt.Name)  // Not sure whether necessary to order by name?
			//Do WriteLine(tmpStream,"    BlockCount:"_sqlmapSt.BlockCount)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"BlockCount")=sqlmapSt.BlockCount
			//Do WriteLine(tmpStream,"    Condition:"_sqlmapSt.Condition)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"Condition")=sqlmapSt.Condition
			//Do WriteLine(tmpStream,"    ConditionFields:"_sqlmapSt.ConditionFields)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"ConditionFields")=sqlmapSt.ConditionFields
			//Do WriteLine(tmpStream,"    ConditionalWithHostVars:"_sqlmapSt.ConditionalWithHostVars)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"ConditionalWithHostVars")=sqlmapSt.ConditionalWithHostVars
			//Do WriteLine(tmpStream,"    Data:")  //%Dictionary.StorageSQLMapDataDefinition
			set keySqlMapData=""
			for {
				set sqlManDefSt=sqlmapSt.Data.GetNext(.keySqlMapData)
				quit:keySqlMapData=""
				continue:'$IsObject(sqlManDefSt)
				//Do WriteLine(tmpStream,"      Name:"_sqlManDefSt.Name)
				//Do WriteLine(tmpStream,"        Delimiter:"_sqlManDefSt.Delimiter)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Data","Name:"_sqlManDefSt.Name,"Delimiter")=sqlManDefSt.Delimiter
				//Do WriteLine(tmpStream,"        Node:"_sqlManDefSt.Node)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Data","Name:"_sqlManDefSt.Name,"Node")=sqlManDefSt.Node
				//Do WriteLine(tmpStream,"        Piece:"_sqlManDefSt.Piece)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Data","Name:"_sqlManDefSt.Name,"Piece")=sqlManDefSt.Piece
				//Do WriteLine(tmpStream,"        RetrievalCode:"_sqlManDefSt.RetrievalCode)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Data","Name:"_sqlManDefSt.Name,"RetrievalCode")=sqlManDefSt.RetrievalCode
			}
			//Do WriteLine(tmpStream,"    Global:"_sqlmapSt.Global)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"Global")=sqlmapSt.Global
			//Do WriteLine(tmpStream,"    PopulationPct:"_sqlmapSt.PopulationPct)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"PopulationPct")=sqlmapSt.PopulationPct
			//Do WriteLine(tmpStream,"    PopulationType:"_sqlmapSt.PopulationType)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"PopulationType")=sqlmapSt.PopulationType
			//Do WriteLine(tmpStream,"    RowIdSpecs:")
			set keyRowIdSpecs=""
			for {
				set IdSpecSt=sqlmapSt.RowIdSpecs.GetNext(.keyRowIdSpecs)
				quit:keyRowIdSpecs=""
				continue:'$IsObject(IdSpecSt)
				
				//Do WriteLine(tmpStream,"      Name:"_IdSpecSt.Name)
				//Do WriteLine(tmpStream,"        Expression:"_IdSpecSt.Expression)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"RowIdSpecs","Name:"_IdSpecSt.Name,"Expression")=IdSpecSt.Expression
				//Do WriteLine(tmpStream,"        Field:"_IdSpecSt.Field)			
				set def("SQLMaps","Name:"_sqlmapSt.Name,"RowIdSpecs","Name:"_IdSpecSt.Name,"Field")=IdSpecSt.Field
			}
			//Do WriteLine(tmpStream,"    RowReference:"_sqlmapSt.RowReference)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"RowReference")=sqlmapSt.RowReference
			//Do WriteLine(tmpStream,"    Structure:"_sqlmapSt.Structure)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"Structure")=sqlmapSt.Structure
			//Do WriteLine(tmpStream,"    Subscripts:")
			set keySubscripts=""
			for {
				set subscriptSt=sqlmapSt.Subscripts.GetNext(.keySubscripts)
				quit:keySubscripts=""
				continue:'$IsObject(subscriptSt)
				//Do WriteLine(tmpStream,"      Name:"_subscriptSt.Name)
				//Do WriteLine(tmpStream,"        AccessType:"_subscriptSt.AccessType)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"AccessType")=subscriptSt.AccessType
				//Do WriteLine(tmpStream,"        Accessvars:")
				set keyAccessvars=""
				for {
					set accessVarsSt=subscriptSt.Accessvars.GetNext(.keyAccessvars)
					quit:keyAccessvars=""
					continue:'$IsObject(accessVarsSt)
					//Do WriteLine(tmpStream,"          Name:"_accessVarsSt.Name)
					//Do WriteLine(tmpStream,"            Code:"_accessVarsSt)
					set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"Accessvars","Name:"_accessVarsSt.Name,"Code")=accessVarsSt.Code
					//Do WriteLine(tmpStream,"            Variable:"_accessVarsSt)
					set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"Accessvars","Name:"_accessVarsSt.Name,"Variable")=accessVarsSt.Variable
				}
				
				//Do WriteLine(tmpStream,"        DataAccess:"_subscriptSt.DataAccess)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"DataAccess")=subscriptSt.DataAccess
				//Do WriteLine(tmpStream,"        Delimiter:"_subscriptSt.Delimiter)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"Delimiter")=subscriptSt.Delimiter
				//Do WriteLine(tmpStream,"        Expression:"_subscriptSt.Expression)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"Expression")=subscriptSt.Expression
				//Do WriteLine(tmpStream,"        Invalidconditions:")
				
				set keyInvalidconditions=""
				for {
					set InvalidconditionSt=subscriptSt.Invalidconditions.GetNext(.keyInvalidconditions)
					quit:keyInvalidconditions=""
					continue:'$IsObject(InvalidconditionSt)
					//Do WriteLine(tmpStream,"          Name:"_InvalidconditionSt.Name)
					//Do WriteLine(tmpStream,"            Expression:"_InvalidconditionSt.Expression)
					set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"Invalidconditions","Name:"_InvalidconditionSt.Name,"Expression")=InvalidconditionSt.Expression
				}
				
				//Do WriteLine(tmpStream,"        LoopInitValue:"_subscriptSt.LoopInitValue)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"LoopInitValue")=subscriptSt.LoopInitValue
				//Do WriteLine(tmpStream,"        NextCode:"_subscriptSt.NextCode)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"NextCode")=subscriptSt.NextCode
				//Do WriteLine(tmpStream,"        NullMarker:"_subscriptSt.NullMarker)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"NullMarker")=subscriptSt.NullMarker
				//Do WriteLine(tmpStream,"        StartValue:"_subscriptSt.StartValue)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"StartValue")=subscriptSt.StartValue
				//Do WriteLine(tmpStream,"        StopExpression:"_subscriptSt.StopExpression)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"StopExpression")=subscriptSt.StopExpression
				//Do WriteLine(tmpStream,"        StopValue:"_subscriptSt.StopValue)
				set def("SQLMaps","Name:"_sqlmapSt.Name,"Subscripts","Name:"_subscriptSt.Name,"StopValue")=subscriptSt.StopValue
				
			}
			//Do WriteLine(tmpStream,"    Type:"_sqlmapSt.Type)
			set def("SQLMaps","Name:"_sqlmapSt.Name,"Type")=sqlmapSt.Type
		}
		
		//Do WriteLine(tmpStream,"SequenceNumber:"_objSt.SequenceNumber)
		//set def("SequenceNumber")=objSt.SequenceNumber - Suppressed
		//Do WriteLine(tmpStream,"SqlChildSub:"_objSt.SqlChildSub)
		set def("SqlChildSub")=objSt.SqlChildSub
		//Do WriteLine(tmpStream,"SqlIdExpression:"_objSt.SqlIdExpression)
		set def("SqlIdExpression")=objSt.SqlIdExpression
		//Do WriteLine(tmpStream,"SqlRowIdName:"_objSt.SqlRowIdName)
		set def("SqlRowIdName")=objSt.SqlRowIdName
		//Do WriteLine(tmpStream,"SqlRowIdProperty:"_objSt.SqlRowIdProperty)
		set def("SqlRowIdProperty")=objSt.SqlRowIdProperty
		//Do WriteLine(tmpStream,"SqlTableNumber:"_objSt.SqlTableNumber)
		set def("SqlTableNumber")=objSt.SqlTableNumber
		//Do WriteLine(tmpStream,"State:"_objSt.State)
		set def("State")=objSt.State
		//Do WriteLine(tmpStream,"StreamLocation:"_objSt.StreamLocation)
		set def("StreamLocation")=objSt.StreamLocation
		// Ensure same output for IRIS
		if objSt.Type="%Library.CacheStorage" {
			set def("Type")="%Storage.Persistent"
		} elseif objSt.Type="%Library.CacheSerialState" {
			set def("Type")="%Storage.Serial"
		} else  {
			set def("Type")=objSt.Type
		}
		//Do WriteLine(tmpStream,"VersionLocation:"_objSt.VersionLocation)
		set def("VersionLocation")=objSt.VersionLocation
		
		set objSt=""
		set sqlmapSt=""
		set subscriptSt=""
		set sqlmapSt=""
		set IdSpecSt=""
		set sqlManDefSt=""
		set propertySt=""
		
		set st1=""
		for {
			set st1=$O(def(st1))
			quit:st1=""
			if st1[":" {
				Do WriteLine(tmpStream,st1)
			} elseif $D(def(st1))#10=1 {  // 1 or 11
				Do WriteLine(tmpStream,st1_":"_def(st1))
			} elseif $D(def(st1))=10 {  // 10
				Do WriteLine(tmpStream,st1_":")
			} else {  // 0
				continue	
			}
			
			set st2=""
			for {
				set st2=$O(def(st1,st2))
				quit:st2=""
				kill pad set $P(pad," ",3)=""
				if st2[":" {
					Do WriteLine(tmpStream,pad_st2)
				} elseif $D(def(st1,st2))#10=1 {  // 1 or 11
					Do WriteLine(tmpStream,pad_st2_":"_def(st1,st2))
				} elseif $D(def(st1,st2))=10 {  // 10
					Do WriteLine(tmpStream,pad_st2_":")
				} else {  // 0
					continue	
				}
				
				set st3=""
				for {
					set st3=$O(def(st1,st2,st3))
					quit:st3=""
					kill pad set $P(pad," ",5)=""
					if st3[":" {
						Do WriteLine(tmpStream,pad_st3)
					} elseif $D(def(st1,st2,st3))#10=1 {  // 1 or 11
						Do WriteLine(tmpStream,pad_st3_":"_def(st1,st2,st3))
					} elseif $D(def(st1,st2,st3))=10 {  // 10
						Do WriteLine(tmpStream,pad_st3_":")
					} else {  // 0
						continue	
					}
					
					set st4=""
					for {
						set st4=$O(def(st1,st2,st3,st4))
						quit:st4=""
						kill pad set $P(pad," ",7)=""
						if st4[":" {
							Do WriteLine(tmpStream,pad_st4)
						} elseif $D(def(st1,st2,st3,st4))#10=1 {  // 1 or 11
							Do WriteLine(tmpStream,pad_st4_":"_def(st1,st2,st3,st4))
						} elseif $D(def(st1,st2,st3,st4))=10 {  // 10
							Do WriteLine(tmpStream,pad_st4_":")
						} else {  // 0
							continue	
						}
						set st5=""
						for {
							set st5=$O(def(st1,st2,st3,st4,st5))
							quit:st5=""
							kill pad set $P(pad," ",9)=""
							if st5[":" {
								Do WriteLine(tmpStream,pad_st5)
							} elseif $D(def(st1,st2,st3,st4,st5))#10=1 {  // 1 or 11
								Do WriteLine(tmpStream,pad_st5_":"_def(st1,st2,st3,st4,st5))
							} elseif $D(def(st1,st2,st3,st4,st5))=10 {  // 10
								Do WriteLine(tmpStream,pad_st5_":")
							} else {  // 0
								continue	
							}
							set st6=""
							for {
								set st6=$O(def(st1,st2,st3,st4,st5,st6))
								quit:st6=""
								kill pad set $P(pad," ",11)=""
								if st6[":" {
									Do WriteLine(tmpStream,pad_st6)
								} elseif $D(def(st1,st2,st3,st4,st5,st6))#10=1 {  // 1 or 11
									Do WriteLine(tmpStream,pad_st6_":"_def(st1,st2,st3,st4,st5,st6))
								} elseif $D(def(st1,st2,st3,st4,st5,st6))=10 {  // 10
									Do WriteLine(tmpStream,pad_st6_":")
								} else {  // 0
									continue	
								}
								set st7=""
								for {
									set st7=$O(def(st1,st2,st3,st4,st5,st6,st7))
									quit:st7=""
									kill pad set $P(pad," ",13)=""
									if st7[":" {
										Do WriteLine(tmpStream,pad_st7)
									} elseif $D(def(st1,st2,st3,st4,st5,st6,st7))#10=1 {  // 1 or 11
										Do WriteLine(tmpStream,pad_st7_":"_def(st1,st2,st3,st4,st5,st6,st7))
									} elseif $D(def(st1,st2,st3,st4,st5,st6,st7))=10 {  // 10
										Do WriteLine(tmpStream,pad_st7_":")
									} else {  // 0
										continue	
									}
									set st8=""
								}
							}
						}
					}
				}
			}
		}
		
		Do tmpStream.Rewind()
		set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
		Do SetSignature(classname, sig,$$$RPTSubTypeStorage,storage)
		Do:includeSource SaveLines(sig)
	}
	Do tmpStream.Clear()
	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>

<Method name="TestStorage">
<Description>
Set tmpStream=##class(%Stream.TmpCharacter).%New()
Do ##class(ompare.SourceHandler.ClassDefinition).TestStorage(classname,tmpStream)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>classname,tmpStream</FormalSpec>
<Implementation><![CDATA[
	//IndexStorage(classname="",tmpStream) //,includeSource)
	
WriteLine(stream,data)  
  W !,data
  Q
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.HL7">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
<p>
Source indexer for HL7 Schemas<br/>
Extracts:
<ol><li>Implemention signatures for highlevel diffs</li>
<li><em>Optionally</em> functional source code lines for full-diff reporting</li>
<li>Creates an summary signature of HL7 independent of the order in which sub-elements and attributes are defined</li>
</ol>
Source line leading and trailing whitespace is ignored.<br/>
<h3>Configuration</h3>
To exclude source code from being captured for detailed reports use schedule configuration option IncludeSourceCode=0<br/>
To control which routines are included in each target namespace for analysis 
update the lookup global using Interoperability LookupTables in SMP or directly.
When first run in each namespace the following exclude defaults will be established:
<example>
^ompare("Config","Exclude","2.1.hl7")=1
^ompare("Config","Exclude","2.2.hl7")=1
^ompare("Config","Exclude","2.3.hl7")=1
^ompare("Config","Exclude","2.4.hl7")=1
^ompare("Config","Exclude","2.5.hl7")=1
^ompare("Config","Exclude","2.5.1.hl7")=1
^ompare("Config","Exclude","2.6.hl7")=1
^ompare("Config","Exclude","2.7.hl7")=1
^ompare("Config","Exclude","2.7.1.hl7")=1
^ompare("Config","Exclude","2.8.hl7")=1
^ompare("Config","Exclude","2.8.1.hl7")=1
^ompare("Config","Exclude","2.8.2.hl7")=1
^ompare("Config","Exclude","HealthShare_2.5.hl7")=1
^ompare("Config","Exclude","ITK.HL7.hl7")=1
</example>
Where value "1" means exclude and "0" means include.<br/>
Exclusions can layer for example to exclude all hl7 schemas with prefix "ompare"
except do include analysis of any hl7 schemas with prefix "ompareV2":
<example>
^ompare("Config","Exclude","ompare*.hl7")=1
^ompare("Config","Exclude","ompareV2*.hl7")=0
</example>]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51853</TimeChanged>
<TimeCreated>64118,44172.791103</TimeCreated>

<Parameter name="DocumentType">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>hl7</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Main entry point for HL7 Source Handler
Do ##class(ompare.SourceHandler).IndexNamespace("OMPARE-TEST",,1)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "HL7"
	#define RPTSubTypeCategory "HL7CAT"
	#define RPTSubTypeMessageGroup "HL7MG"
	#define RPTSubTypeMessageEvent "HL7ME"
	#define RPTSubTypeMessageType "HL7MT"
	#define RPTSubTypeMessageStructure "HL7MS"
	#define RPTSubTypeSegmentStructure "HL7SS"
	#define RPTSubTypeDataType "HL7DT"
	#define RPTSubTypeCodeTable "HL7CT"
	#define RPTSubTypeConfig "CFG"
	#define RPTItemConfigMapped "IsMapped"
	#define RPTItemConfigSourceControlled "IsSourceControlled"
	#define RPTItemConfigSourceVersion "SrcVer"
	
	if '$IsObject(schedule) {
		set schedule=##class(ompare.Schedule).%New()
	}
	// Testing
    // Do ##class(ompare.SourceHandler.HL7).IndexNamespace("Namespace",0,0)
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Routine Source Handler")
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
    
	
	// Invoke sub-class extension code
	try {
		Do IndexerMain
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.HL7Definition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	Quit ret
SetIsMapped(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:'##class(%Dictionary.CompiledMethod).%ExistsId("%Studio.SourceControl.ISC||IsMapped")
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigMapped)=##class(%Studio.SourceControl.ISC).IsMapped(typeName_".HL7")
	quit
SetIsSourceControlled(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:$Data(^Sources)<11
	quit:$$SourceControlClass^%occLibrary($Namespace)'="%Studio.SourceControl.ISC"
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceControlled)=##class(%File).Exists(##class(%Studio.SourceControl.ISC).ExtName(typeName_".HL7"))
	quit
SetSourceVersion(typeName,data)
	quit:$$$RPTType=""
	quit:typeName=""
	set data=$ZSTRIP(data,"<>W")
	set:$E(data,1)=":" data=$ZSTRIP($E(data,2,*),"<>W")
	quit:data=""
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceVersion)=data
	quit
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  // Intercept Source Control Tokens
  // eg: $I + d: //some/org/project/product/BASE/rtn/PRTDR9ORG.rtn#1 $
  // Converts to $I + d$
  set dataNoTokenVersion=""
  if schedule.SrcVersionTokenStart'="" {
	if schedule.SrcVersionTokenEnd'="" {
		set pattern=".E1"""_schedule.SrcVersionTokenStart_"""1.E1"""_schedule.SrcVersionTokenEnd_""""
  		for {
		  quit:data'?@pattern
		  set dataNoTokenVersion=dataNoTokenVersion_$P(data,schedule.SrcVersionTokenStart)_schedule.SrcVersionTokenStart_schedule.SrcVersionTokenEnd
		  set data=$P($P(data,schedule.SrcVersionTokenStart,2,999999),schedule.SrcVersionTokenEnd,2,999999)
	  	}
	} elseif data[schedule.SrcVersionTokenStart {
		// The source control token effectively matches to the end of the line
		set data=$P(data,schedule.SrcVersionTokenStart)	
	}
  }
  // Include remainder of line after token end if token version content removed
  set:$L(dataNoTokenVersion)>0 data=dataNoTokenVersion_data
  
  
  // strip any terminating whitespace from line
  set data=$ZSTRIP(data,">W")
  // reformatting lines section
  Do stream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value="")
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting HL7 schema components from this point forward.
	******************************/
	// Default exclusions in this namespace
	// Start set once in first run namespace
	set hasConfig=0
	set testExclude=""
	for {
		set testExclude=$O(^ompare("Config","Exclude",testExclude))
		quit:testExclude=""
		if $E(testExclude,*-3,*)=".hl7" {
			set hasConfig=1
			quit  // exit on first encountered
		}
	}
	if 'hasConfig {
		// ignore system routines
		set ^ompare("Config","Exclude","2.1.hl7")=1
		set ^ompare("Config","Exclude","2.2.hl7")=1
		set ^ompare("Config","Exclude","2.3.hl7")=1
		set ^ompare("Config","Exclude","2.3.1.hl7")=1
		set ^ompare("Config","Exclude","2.4.hl7")=1
		set ^ompare("Config","Exclude","2.5.hl7")=1
		set ^ompare("Config","Exclude","2.5.1.hl7")=1
		set ^ompare("Config","Exclude","2.6.hl7")=1
		set ^ompare("Config","Exclude","2.7.hl7")=1
		set ^ompare("Config","Exclude","2.7.1.hl7")=1
		set ^ompare("Config","Exclude","2.8.hl7")=1
		set ^ompare("Config","Exclude","2.8.1.hl7")=1
		set ^ompare("Config","Exclude","2.8.2.hl7")=1
		set ^ompare("Config","Exclude","HealthShare_2.5.hl7")=1
		set ^ompare("Config","Exclude","ITK.hl7")=1
	}
	// End set once in first run namespace

	set hl7name=""
	for {
		set hl7name=$Order(^EnsHL7.Schema(hl7name))
		quit:hl7name=""
		
		if $$IsExcluded(hl7name_".hl7",.reason) {
			Do:logging Log("Ignore """_hl7name_""" matches filter",reason)
			continue	
		}		
		// Simple - Reindex ALL HL7 on demand
		Do:logging Log("ProcessRoutine",hl7name_$C(13,10))
		
		Do Indexhl7(hl7name,tmpStream,includeSource)
	}
	Quit
Indexhl7(hl7name,tmpStream,includeSource)
	Quit:hl7name=""
	Quit:'$IsObject(tmpStream)
	
	Do tmpStream.Clear()
	
	// Replace existing data
	set line=0
	
	set hl7Stream=##class(%Stream.TmpCharacter).%New()
	do ##class(%SYSTEM.OBJ).ExportToStream(hl7name_".HL7",hl7Stream,"/diffexport=1")
	do hl7Stream.Rewind()
	for {
		quit:hl7Stream.AtEnd
		set fragment=$ZSTRIP(hl7Stream.ReadLine(),"<>W")
		continue:$L(fragment)=0
		set elementName=$E($P(fragment," "),2,*)
		
		
		// skip start lines
		// <?xml version="1.0" encoding="UTF-8"?>
		// <Export
		// <Document
		continue:elementName="?xml"
		continue:elementName="Export"
		continue:elementName="Document"
		
		
		// TODO - Review subtypes
		if elementName="Category" {
			set subtype=$$$RPTSubTypeCategory  //"HL7CAT"
		} elseif elementName="MessageGroup" {  //Y
			set subtype=$$$RPTSubTypeMessageGroup  //"HL7MG" 1
		} elseif elementName="MessageEvent" {  //Y
			set subtype=$$$RPTSubTypeMessageEvent  //"HL7ME"  1
		} elseif elementName="MessageType" {
			set subtype=$$$RPTSubTypeMessageType  //"HL7MT" // 0
		} elseif elementName="MessageStructure" {  //1
			set subtype=$$$RPTSubTypeMessageStructure // "HL7MS"
		} elseif elementName="SegmentStructure" {  //1
			// Multi
			set subtype=$$$RPTSubTypeSegmentStructure //"HL7SS"			
		} elseif elementName="DataType" {
			// Multi
			set subtype=$$$RPTSubTypeDataType //HL7DT  1
		} elseif elementName="CodeTable" {
			// multi
			set subtype=$$$RPTSubTypeCodeTable //HL7CT
		} else {
			set subtype="Unknown"
		}
		
		/*
			#define RPTSubTypeCategory "HL7CAT"
	#define RPTSubTypeMessageGroup "HL7MG"
	#define RPTSubTypeMessageEvent "HL7ME"
	#define RPTSubTypeMessageType "HL7MT"
	#define RPTSubTypeMessageStructure "HL7MS"
	#define RPTSubTypeDataType "HL7DT"
	#define RPTSubTypeCodeTable "HL7CT"
		*/
		do IndexContent(hl7name,subtype, tmpStream,hl7Stream,includeSource,fragment)
	
	}
	
	set hl7Summary=hl7name
	// After completing detail for line labels make a signature for the whole routine
	// Note that the order of the line labels is not functionally important
	for subtypeKey=$$$RPTSubTypeCategory,$$$RPTSubTypeMessageGroup,$$$RPTSubTypeMessageEvent,$$$RPTSubTypeMessageType,$$$RPTSubTypeMessageStructure,$$$RPTSubTypeSegmentStructure,$$$RPTSubTypeDataType,$$$RPTSubTypeCodeTable {
	
		set currentItem=""
		for {
			Quit:'$$NextSignature(hl7name,.sig,subtypeKey,.currentItem)
			set hl7Summary=hl7Summary_";"_currentItem_":"_sig
		}
	}
	
	Do SetSignature(hl7name, $SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1Hash(hl7Summary)))
	
	Do SetIsMapped(hl7name)
	Do SetIsSourceControlled(hl7name)
	
	Quit
	;From
	;	"<Category name=""Test"" desc=""Description"" />"
	; generates
	;   aryout("desc")="Description"
	;   aryout("name")="Test"
SplitAttributes(xmlline,aryout)
	kill aryout
	set xmlline=$ZSTRIP(xmlline,"<>W")
	if $E(xmlline,1)="<" set xmlline=$ZSTRIP($P(xmlline," ",2,999),"<W")
	for {
		quit:xmlline=""
		quit:xmlline="/>"
		quit:xmlline=">"
		set xmlatname=$ZSTRIP($P(xmlline,"="),">W")
		set xmlline=$ZSTRIP($P(xmlline,"=",2,9999),"<W")
		continue:xmlatname=""
		set xmlquot=$E(xmlline,1)
		continue:xmlquot'?1(1"""",1"'")
		set xmlatvalue=$P(xmlline,xmlquot,2)
		set xmlline=$ZSTRIP($P(xmlline,xmlquot,3,99999),"<W")
		set aryout(xmlatname)=xmlatvalue
	}
	Quit

	;
	; Indexer for:
	; * Category - Top level tag
	; * MessageStructure
	; * MessageGroup
	; * MessageEvent
	; * MessageType
	; * DataType
	; * CodeTable
IndexContent(hl7name,subtype, sigStream,hl7Stream,includeSource,fragment,source)
	
	Do sigStream.Clear()
	set line=0
	set fragment=$ZSTRIP(fragment,"<>W")
	set rootElementStart=$P($P($P($P(fragment,"<",2)," "),"/"),">")
	Kill aryout
	//W:subtype="HL7MT" !,"rootElementStart:",rootElementStart
	set isMultiLine=$S(subtype="HL7CAT":0,$E(fragment,*-1,*)="/>":0,1:1)
	// Both multi and single
	do SplitAttributes(fragment,.aryout)
	set (xmlatname,subtypeName)=$G(aryout("name"))
	quit:xmlatname=""  // If this hit a comment <!-- --> would be quite unlikely to pass this step.

	Do:logging Log("xmlatname",xmlatname_$C(13,10))
	Do:logging Log("subtype",subtype_$C(13,10))
	
	set xmlatname=""
	for {
		set xmlatname=$O(aryout(xmlatname),1,xmlatvalue)
		quit:xmlatname=""
		Do WriteLine(sigStream,xmlatname_": "_xmlatvalue)
	}
	if 'isMultiLine {
		if sigStream.Size>0 {
			Do sigStream.Rewind()
			set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(sigStream))
			Do SetSignature(hl7name, sig,subtype,subtypeName)
			Do:includeSource SaveLines(sig)
			Do sigStream.Clear()
		}
		quit  // end for single line element
	}
	set pad="                                                 "
	set level=1
	for {
		quit:hl7Stream.AtEnd
		set fragment=$ZSTRIP(hl7Stream.ReadLine(),"<>W")
		//W:$E(fragment,1,2)="</" fragment
		quit:fragment=("</"_rootElementStart_">")
		
		if $E(fragment,1,2)="</" {
			kill level(level)
			set level=level-1
			continue
		}
		if $E(fragment,1)="<" {
			set innerElement=$P($P($P($P(fragment,"<",2)," "),"/"),">")
			if innerElement'="" {
				set level($I(level))=innerElement
				Do WriteLine(sigStream,$E(pad,1,level*2)_innerElement_":")
				do SplitAttributes(fragment,.aryout)
				//set xmlatname=$G(aryout("name"))
				//quit:xmlatname=""
				set xmlatname=""
				for {
					set xmlatname=$O(aryout(xmlatname),1,xmlatvalue)
					quit:xmlatname=""
					Do WriteLine(sigStream,$E(pad,1,(level*2)+2)_xmlatname_": "_xmlatvalue)
				}
				
			}
			if $E(fragment,*-1,*)="/>" {
				kill level(level)
				set level=level-1
				continue	
			}
		} else {
			// attributes spanning multiple lines
			do SplitAttributes(fragment,.aryout)
			set xmlatname=""
			for {
				set xmlatname=$O(aryout(xmlatname),1,xmlatvalue)
				quit:xmlatname=""
				Do WriteLine(sigStream,$E(pad,1,(level*2)+2)_xmlatname_": "_xmlatvalue)
			}
		}
	}
	if sigStream.Size>0 {
		Do sigStream.Rewind()
		set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(sigStream))
		Do SetSignature(hl7name, sig,subtype,subtypeName)
		Do:includeSource SaveLines(sig)
		Do sigStream.Clear()
	}
	
	
	
	Quit

	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>

<Method name="TSplitAttributes">
<ClassMethod>1</ClassMethod>
<FormalSpec>xmlline,aryout</FormalSpec>
<Implementation><![CDATA[
	kill aryout
	set xmlline=$ZSTRIP(xmlline,"<>W")
	if $E(xmlline,1)="<" set xmlline=$ZSTRIP($P(xmlline," ",2,999),"<W")
	for {
		quit:xmlline=""
		quit:xmlline="/>"
		quit:xmlline=">"
		set xmlatname=$ZSTRIP($P(xmlline,"="),">W")
		set xmlline=$ZSTRIP($P(xmlline,"=",2,9999),"<W")
		continue:xmlatname=""
		set xmlquot=$E(xmlline,1)
		continue:xmlquot'?1(1"""",1"'")
		set xmlatvalue=$P(xmlline,xmlquot,2)
		set xmlline=$ZSTRIP($P(xmlline,xmlquot,3,99999),"<W")
		set aryout(xmlatname)=xmlatvalue
	}
	Quit
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Include">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
<p>
Source indexer for Include (*.inc) documents that contain compiler macros.<br/>
Extracts:
<ol><li>Implemention signatures for highlevel diffs</li>
<li><em>Optionally</em> functional source code lines for full-diff reporting</li>
<li>For <em>import</em>, <em>define</em> and <em>deflarg</em> generates value signatures independent of the order in which they are defined</li>
<li>In parallel to support difference of sequence sensitive and conditional block a full document diff is also included</li>
</ol>
Source line leading and trailing whitespace is ignored.<br/>
Multi-line <em>Define</em> definitions are followed by their <em>##continue</em> directive
<h3>Configuration</h3>
To exclude source code from being captured for detailed reports use schedule configuration option IncludeSourceCode=0<br/>
To control which <em>include</em> documnts are profiled in each target namespace for analysis 
update the <em>ompare</em> or lookup global using Interoperability LookupTables in SMP or directly.
When first run in each namespace the following exclude defaults will be established:
<example>
^ompare("Config","Exclude","%")=1
</example>
Where value "1" means exclude and "0" means include.<br/>
Exclusions can layer for example to exclude all <em>include</em> documents with prefix "ompare"
except do include analysis of any <em>include</em> documents with prefix "ompareV2":
<example>
^ompare("Config","Exclude","ompare*.inc")=1
^ompare("Config","Exclude","ompareV2*.inc")=0
</example>]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51861</TimeChanged>
<TimeCreated>64118,44172.791103</TimeCreated>

<Parameter name="DocumentType">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>inc</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Main entry point for INC Source Handler
Do ##class(ompare.SourceHandler).IndexNamespace("OMPARE-TEST",,1)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "INC"
	#define RPTSubTypeDefine "INCDF"
	#define RPTSubTypeDef1arg "INCDA"
	#define RPTSubTypeInclude "INCIN"
	#define RPTSubTypeFull "INCFL"
	#define RPTSubTypeConfig "CFG"
	#define RPTItemConfigMapped "IsMapped"
	#define RPTItemConfigSourceControlled "IsSourceControlled"
	#define RPTItemConfigSourceVersion "SrcVer"
	
	if '$IsObject(schedule) {
		set schedule=##class(ompare.Schedule).%New()
	}
	// Testing
    // Do ##class(ompare.SourceHandler.Include).IndexNamespace("Namespace",0,0)
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Routine Source Handler")
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
    
	
	// Invoke sub-class extension code
	try {
		Do IndexerMain
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.Include Definition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	Quit ret
SetIsMapped(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:'##class(%Dictionary.CompiledMethod).%ExistsId("%Studio.SourceControl.ISC||IsMapped")
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigMapped)=##class(%Studio.SourceControl.ISC).IsMapped(typeName_".INC")
	quit
SetIsSourceControlled(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:$Data(^Sources)<11
	quit:$$SourceControlClass^%occLibrary($Namespace)'="%Studio.SourceControl.ISC"
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceControlled)=##class(%File).Exists(##class(%Studio.SourceControl.ISC).ExtName(typeName_".INC"))
	quit
SetSourceVersion(typeName,data)
	quit:$$$RPTType=""
	quit:typeName=""
	set data=$ZSTRIP(data,"<>W")
	set:$E(data,1)=":" data=$ZSTRIP($E(data,2,*),"<>W")
	quit:data=""
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceVersion)=data
	quit
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  // Intercept Source Control Tokens
  // eg: $I + d: //some/org/project/product/BASE/rtn/PRTDR9ORG.rtn#1 $
  // Converts to $I + d$
  set dataNoTokenVersion=""
  if schedule.SrcVersionTokenStart'="" {
	if schedule.SrcVersionTokenEnd'="" {
		set pattern=".E1"""_schedule.SrcVersionTokenStart_"""1.E1"""_schedule.SrcVersionTokenEnd_""""
  		for {
		  quit:data'?@pattern
		  set dataNoTokenVersion=dataNoTokenVersion_$P(data,schedule.SrcVersionTokenStart)_schedule.SrcVersionTokenStart_schedule.SrcVersionTokenEnd
		  set data=$P($P(data,schedule.SrcVersionTokenStart,2,999999),schedule.SrcVersionTokenEnd,2,999999)
	  	}
	} elseif data[schedule.SrcVersionTokenStart {
		// The source control token effectively matches to the end of the line
		set data=$P(data,schedule.SrcVersionTokenStart)	
	}
  }
  // Include remainder of line after token end if token version content removed
  set:$L(dataNoTokenVersion)>0 data=dataNoTokenVersion_data
  
  
  // strip any terminating whitespace from line
  set data=$ZSTRIP(data,">W")
  // reformatting lines section
  Do stream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value="")
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
DoSig(incname,stream,subtype,subtypename)
	if stream.Size>0 {
		Do stream.Rewind()
		set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(stream))
		Do SetSignature(incname, sig,subtype,subtypename)
		Do:includeSource SaveLines(sig)
		Do stream.Clear()
	}
	quit
	; Extract name value pair delimeted by some whitespace
DoSplit(data,subtype,subname,subvalue,isContinue)
	set (subtype,subname,subvalue)=""
	if $E(data,1)="#" {
		set subtype=$ZCVT($P($P($P(data,$C(9)),$C(32)),$C(160)),"L")
		set data=$E(data,$L(subtype)+1,*)
	}
	set (subname,subvalue)=""
	set data=$ZSTRIP(data,"<W")
	set subname=$P($P($P(data,$C(9)),$C(32)),$C(160))
	set subvalue=$ZSTRIP($E(data,$L(subname)+1,*),"<>W")
	if $ZCVT($E(subvalue,*-9,*),"L")="##continue" {
		set isContinue=1
		set subvalue=$ZSTRIP($E(subvalue,1,*-10),">W")	
	} else {
		set isContinue=0	
	}
	quit
IndexerMain
	/*****************************
	 End Template
	******************************/
	// Default exclusions in this namespace
	// Start set once in first run namespace
	set hasConfig=0
	set testExclude=""
	for {
		set testExclude=$O(^ompare("Config","Exclude",testExclude))
		quit:testExclude=""
		if $E(testExclude,*-3,*)=".inc" {
			set hasConfig=1
			quit  // exit on first encountered
		}
	}
	if 'hasConfig {
		// ignore system routines
		set ^ompare("Config","Exclude","%*.inc")=1
		set ^ompare("Config","Exclude","HS*.inc")=1
		set ^ompare("Config","Exclude","Ens*.inc")=1
		set ^ompare("Config","Exclude","SchemaMap.inc")=1
	}
	// End set once in first run namespace

	set incname=""
	for {
		set incname=$Order(^rINC(incname))
		quit:incname=""
		
		if $$IsExcluded(incname_".inc",.reason) {
			Do:logging Log("Ignore """_incname_""" matches filter",reason)
			continue	
		}		
		// Simple - Reindex ALL INC on demand
		Do:logging Log("ProcessINC",incname_$C(13,10))
		
		Do Indexinc(incname,tmpStream,includeSource)
	}
	Quit
Indexinc(incname,tmpStream,includeSource)
	Quit:incname=""
	Quit:'$IsObject(tmpStream)
	
	set emptySig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1Hash(""))
	// Use tmpStream for Full inc context
	Do tmpStream.Clear()
	
	// Replace existing data
	set line=0
	
	set incStreamPart=##class(%Stream.TmpCharacter).%New()
	
	set k3=0,subtype=0
	for {
		set k3=$O(^rINC(incname,0,k3),1,data)
		quit:k3'?1.N  // Stop if hit "SIZE" node
		
		set data=$ZSTRIP(data,"<>W")
		
		if $L(data)=0 continue  // ignore empty line
		if $E(data,1)=";"  continue // ignore comment
		if $E(data,1,2)="#;"  continue // ignore comment
		if $E(data,1,2)="//"  continue  // ignore comment
		
		Do tmpStream.WriteLine(data)  // Append to full stream
		
		
		
		Do DoSplit(data,.tsubtype,.tsubname,.tsubvalue,.isContinue)
		
		//W !,"data=",data
		//w !,"  tsubtype=",tsubtype
		//W !,"  tsubname=",tsubname
		//W !,"  tsubvalue=",tsubvalue
		//W !,"  isContinue=",isContinue
		//W !,"  subtype=",subtype
		//W !,"----------------"

		// Filter comments
		if subtype=0 {
			
			if tsubtype="#define" {
				set subtype=$$$RPTSubTypeDefine
				Do incStreamPart.Rewind()
				set line=0
				set subtypename=tsubname
				
				// is the end of the line is ##continue
				if 'isContinue {
					Do WriteLine(incStreamPart,tsubvalue)
					Do DoSig(incname,incStreamPart,subtype,tsubname)
					set subtype=0
					
				} else {
					Do WriteLine(incStreamPart,tsubvalue)	
				}
			} elseif tsubtype="#def1arg" {
				set subtype=$$$RPTSubTypeDef1arg
				Do incStreamPart.Rewind()
				set line=0
				Do WriteLine(incStreamPart,tsubvalue)
				Do DoSig(incname,incStreamPart,subtype,tsubname)
				set subtype=0
			} elseif tsubtype="#if" {
				set ifstack=1
				set subtype="#if"
				Do incStreamPart.Rewind()
				set line=0
				// Skip stuff to the corresponding endif	
			} elseif tsubtype="#include" {
				//to do save individual??
				//set subtype=$$$RPTSubTypeInclude
				Do incStreamPart.Rewind()
				set line=0
				Do SetSignature(incname, emptySig,$$$RPTSubTypeInclude,tsubname)
				set subtype=0	
			} else {
				Do:logging Log("ProcessINC",incname_"::Unknown Include condition ",tsubtype)	
			}
		} elseif subtype=$$$RPTSubTypeDefine {
			// Expect this is "continued" by previous line
			Do:$L(data)>0 WriteLine(incStreamPart,data)
			if $E(data,*-9,*)'="##continue" {
				set mode=0
				Do DoSig(incname,incStreamPart,subtype,subtypename)
				set subtype=0
			}	
		} elseif subtype="#if" {
			// Allow for nested IF
			if tsubtype="#endif" {
				set ifstack=ifstack-1
				if ifstack<1 {
					set subtype=0	
				}
			} elseif tsubtype="#if" {
				set ifstack=ifstack+1
			}
		} else {
			Do:logging Log("ProcessINC",incname_"::Unknown subtype",subtype)
		}
	}
	
	do tmpStream.Rewind()
	do incStreamPart.Rewind()
	set line=0
	for {
		quit:tmpStream.AtEnd
		do WriteLine(incStreamPart,tmpStream.ReadLine())	
	}
	do incStreamPart.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(incStreamPart))
	do incStreamPart.Rewind()
	Do SetSignature(incname, sig,$$$RPTSubTypeFull,"FULL")
	Do:includeSource SaveLines(sig)
	Do SetSignature(incname, sig)

	Do SetIsMapped(incname)
	Do SetIsSourceControlled(incname)
	Quit
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Lookup">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Source Handler for Interoperability Lookup Tables.
Builds signature profiles for Keys and their Values.<br/>
When first run in each namespace no default exclusions are established.<br/>
To exclude a LookupTable use:
<example>
^ompare("Config","Exclude","ompare.*.lut")=1
^ompare("Config","Exclude","ompare.Exclude.lut")=0
</example>
Where value "1" means exclude and "0" means include.<br/>
Above exclusions are layered to exclude all lookup tables starting within name <em>ompare</em>
except do include analysis of the <em>ompare.Exclude</em> table.]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51871</TimeChanged>
<TimeCreated>64118,51521.130289</TimeCreated>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>LUT</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Main entry point for Ensemble Lookup Table Source Handler
do ##class(ompare.SourceHandler.Lookup).IndexNamespace($namespace,1)</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "LUT"
	#define RPTSubTypeEnsLookupKey "Key"
	
	// Testing
    // Do ##class(ompare.SourceHandler.EnsLookupTable).IndexNamespace("INTEG-MARS",0,0)
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Lookup Source Handler")
	
		New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
		try {	
			 // Generates <NAMESPACE> error if namespace doesn't exist
			 // Generate <PROTECT> error if user does not have access privilage
			set $NAMESPACE=namespace
		} catch errobj {
			// Name
			// Code
			// Location
			// Data
			if errobj.Name="<NAMESPACE>" {
				set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
			} elseif errobj.Name="" {
				set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
			} else {
				set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
			}
		}
		Quit:$$$ISERR(ret) ret
	
	// Invoke sub-class extension code
	Do IndexerMain
	
	Quit ret
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  Do tmpStream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value="")
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	set reason=""
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/
	
	set tablename=""
	for {
		set tablename=$Order(^Ens.LookupTable(tablename))
		quit:tablename=""
		if $$IsExcluded(tablename_".lut",.reason) {
			Do:logging Log("Ignore """_tablename_""" matches ",reason)
			continue
		}
		Do:logging Log("IndexLookup "_tablename)
		Do IndexLookup(tablename,tmpStream)
	}
	Quit
IndexLookup(tablename,tmpStream)
	Quit:tablename=""
	Quit:'$IsObject(tmpStream)
	
	Do tmpStream.Clear()

	// Replace existing data
	set line=0
	
	// Simple - Replacing data
	set key=""
	for {
		set key=$Order(^Ens.LookupTable(tablename,key),+1,data)	
		quit:key=""
		
		// Saving the actual values instead of signatures.
		// Rationale: Ensemble Lookups values tend to be much smaller than a corresponding 20 character signature
		// The comparison code for reports will automatically compare the stored values
		// Revert "Null" entries to empty strings on export
		set:data=$C(0) data=""
		Do WriteLine(tmpStream,key_"¬¬"_data)
	}
	// Use a Stream as we don't know how many entries are required in a lookup table
	Do tmpStream.Rewind()
	//Do SetSignature(tablename,$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream)))
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature(tablename, sig)
	Do SaveLines(sig)  // Efficiency when using DataSrc instead of multiple keys for every day when lookups change infrequently
	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>

<Parameter name="SrcVer">
<Description>
Location and Revision of this file in Perforce (Auto-updating)</Description>
<Default>$Id$</Default>
</Parameter>
</Class>


<Class name="ompare.SourceHandler.Mapping">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Source Handler for collecting Global, Routine and Package Mappings that can
be used for reporting diffrences of Namespace configuration between instances.
No configuration options.]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51880</TimeChanged>
<TimeCreated>64373,64863.15838</TimeCreated>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>NSMAP</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Do not invoke supporting methods on this class definition</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	if '$IsObject(schedule) {
		set schedule=##class(ompare.Schedule).%New()
	}
	#define RPTType "NSMAP"
	#define RPTNameDefault "Default"
	#define RPTNameGlobal "Globals"
	#define RPTNameRoutine "Routines"
	#define RPTNamePackage "Packages"
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	#dim tmpStreamSub as %Stream.TmpCharacter
	Set tmpStreamSub=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Mapping Source Handler")
	Quit:'##class(%SYS.Namespace).Exists(namespace) $$$ERROR(5001,"Namespace "_namespace_" does not exist")
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE="%SYS"  // In this specific scenario need access to the SYS Namespace to run privilaged functionality
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		set ret=$$$ERROR(5001,"No access for user "_$USERNAME_" to %SYS namespace ")
	}
	Quit:$$$ISERR(ret) ret
	
	// Invoke sub-class extension code
	Do IndexerMain
	
	Quit ret
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  Do tmpStream.WriteLine(data)
  Do:includeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value)
	W !,label,":",value
	Quit
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/	
	// Default Section
	Set line=0
	Set tSC=##Class(Config.Namespaces).Get(namespace,.properties)
	Do tmpStream.Clear()
	Do WriteLine(tmpStream,"GlobalDB: "_$G(properties("Globals")))
	Do WriteLine(tmpStream,"RoutineDB: "_$G(properties("Routines")))
	Do WriteLine(tmpStream,"TempDB: "_$G(properties("TempGlobals")))
	// Use a Stream as we don't know how many entries are required in a lookup table
	Do tmpStream.Rewind()
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature($$$RPTNameDefault, sig)
	Do:includeSource SaveLines(sig)
	
	// Global Map Section
	// Query: Config.MapGlobals:List(Namespace)
    //   Name, Global, Subscript, Database
    Set line=0
	Do tmpStream.Clear()
	set rs=##class(%ResultSet).%New("Config.MapGlobals:List")
	do rs.Execute(namespace)
	for {
		quit:'rs.Next()
		set rName=$G(rs.Data("Name"))
		continue:rName=""
		set rGlobal=$G(rs.Data("Global"))
		continue:rGlobal=""
		set rSubscript=$G(rs.Data("Subscript"))
		set rDatabase=$G(rs.Data("Database"))
		Do WriteLine(tmpStream,"Global:"_rGlobal)
		Do WriteLine(tmpStream,"  Subscript="_rSubscript)
		Do WriteLine(tmpStream,"  Database="_rDatabase)
	}
	set rs=""
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature($$$RPTNameGlobal, sig)
	Do:includeSource SaveLines(sig)

	// Package Map Section
	// Query: Config.MapPackages:List(Namespace)
    //   Name, Package, Database
    Set line=0
    Do tmpStream.Clear()
	set rs=##class(%ResultSet).%New("Config.MapPackages:List")
	do rs.Execute(namespace)
	for {
		quit:'rs.Next()
		set rName=$G(rs.Data("Name"))
		continue:rName=""
		set rPackage=$G(rs.Data("Package"))
		continue:rPackage=""
		set rDatabase=$G(rs.Data("Database"))
		Do WriteLine(tmpStream,"Package:"_rPackage)
		Do WriteLine(tmpStream,"  Database="_rDatabase)
	}
	set rs=""
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature($$$RPTNamePackage, sig)
	Do:includeSource SaveLines(sig)

	// Routines Map Section
	// Query: Config.MapRoutines:List(Namespace)
  	//   Name, Routine, Type, Database
	Set line=0
	Do tmpStream.Clear()
	set rs=##class(%ResultSet).%New("Config.MapRoutines:List")
	do rs.Execute(namespace)
	for {
		quit:'rs.Next()
		set rName=$G(rs.Data("Name"))
		continue:rName=""
		set rRoutine=$G(rs.Data("Routine"))
		continue:rRoutine=""
		set rDatabase=$G(rs.Data("Database"))
		Do WriteLine(tmpStream,"Routine:"_rRoutine)
		Do WriteLine(tmpStream,"  Database="_rDatabase)
	}
	set rs=""
	set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
	Do SetSignature($$$RPTNameRoutine, sig)
	Do:includeSource SaveLines(sig)
	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Namespace">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Capture product deployment metadata context about the Namespace being analysed.
These minimum contexts will make it simpler to report configuration for comparing accross environments.
The following diagram shows the relationship of deployment concepts:
<ol><li>Organisation - (eg: ACME and MEEP)</li>
<li>System - (eg: PlanA and PlanB)</li>
<li>Environment - (eg: BASE, TEST, UAT, PROD)</li></ol>
In the example code is developed for two customers on a single shared inhouse development instance.
Each customer provides 3 seperate instances to support TEST, UAT and PROD stages.
The cylinders represent namespaces. In the example each logical product deployment consists of two participating namespaces.
Components for PlanA (System) occupy one namespace and components PlanB (System) occupy the other.
<img src="data:image/png;base64, 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"/><br/>
Metadata is added to each target namespace for next and subsequent analysis.
Update the lookup global using Interoperability LookupTables or Global Explorer in SMP or directly.
When first run in each namespace the following blank defaults will be added if no previous setting is detected.
<example>
^Ens.LookupTable("ompare.Namespace","Organisation")=""
^Ens.LookupTable("ompare.Namespace","System")=""
^Ens.LookupTable("ompare.Namespace","Environment")=""
</example>
A complete configuration would be:
<example>
^Ens.LookupTable("ompare.Namespace","Organisation")="MEEP"
^Ens.LookupTable("ompare.Namespace","System")="PlanA"
^Ens.LookupTable("ompare.Namespace","Environment")="TEST"
</example>]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51889</TimeChanged>
<TimeCreated>64373,61036.282971</TimeCreated>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
</Parameter>

<Method name="IndexNamespace">
<Description>
Do not invoke supporting methods on this class definition</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "?"
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Namespace Source Handler")
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
	
	
	// Invoke sub-class extension code
	//Do IndexerMain
	try {
		// Invoke sub-class extension code
		Do IndexerMain  //(logging, includeSource)
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.ClassDefinition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	
	Quit ret
Log(label, value)
	W !,label,":",value
	Quit
IndexerMain
	// Defaults
	if '$Data(^Ens.LookupTable("ompare.Namespace","Organisation")) {
		set ^Ens.LookupTable("ompare.Namespace","Organisation")=""
	}
	if '$Data(^Ens.LookupTable("ompare.Namespace","System")) {
		set ^Ens.LookupTable("ompare.Namespace","System")=""	
	}
	if '$Data(^Ens.LookupTable("ompare.Namespace","Environment")) {
		set ^Ens.LookupTable("ompare.Namespace","Environment")=""	
	}

	// Only record data on top node of ^||Data
	
	// Current Date
	set $P(^||Data,"^")=+$H
	
	// Current Time
	set $P(^||Data,"^",2)=$P($H,",",2)
	
	// Active Source Control Class
	set sourceControlClass=$G(^SYS("SourceControlClass"))
	if sourceControlClass'="" {
		set $P(^||Data,"^",3)=sourceControlClass
	} else {
		do:logging Log(label, value)
	}
	
	// Check for whether this is %Studio.SourceControl.ISC or empty
	if sourceControlClass'="" {
		if ##class(%Dictionary.CompiledMethod).%ExistsId(sourceControlClass_"||Locked") {
			// Is SourceControl Locked
			set $P(^||Data,"^",4)=$$Escape($CLASSMETHOD(sourceControlClass,"Locked"))
		}
		if ##class(%Dictionary.CompiledMethod).%ExistsId(sourceControlClass_"||Disconnected") {
			// Is SourceControl Connected
			set $P(^||Data,"^",5)=$$Escape($CLASSMETHOD(sourceControlClass,"Disconnected"))
		}
	} else {
		do:logging Log("Namespace Handler","Source Control Class not found")
	}
	
	if ##class(%Dictionary.CompiledClass).%ExistsId("Ens.Director") {
		// Current Production Name
		Do ##class(Ens.Director).GetProductionStatus(.pProduction,.pStatus)
		set $P(^||Data,"^",6)=$$Escape(pProduction)
		do:logging Log("Namespace","Current Production: "_pProduction)
	}
	
	// Organisation
	set $P(^||Data,"^",7)=$$Escape(^Ens.LookupTable("ompare.Namespace","Organisation"))
	// System
	set $P(^||Data,"^",8)=$$Escape(^Ens.LookupTable("ompare.Namespace","System"))
	// Environment
	set $P(^||Data,"^",9)=$$Escape(^Ens.LookupTable("ompare.Namespace","Environment"))
	
	// Role
	set $P(^||Data,"^",10)=$$Escape($G(^SYS("SourceControl","Misc","SU_Role")))
	// Tags
	set $P(^||Data,"^",11)=$$Escape($G(^SYS("SourceControl","Misc","SU_Tags")))
	// Depreciate Comment
	set $P(^||Data,"^",12)=$$Escape($G(^SYS("SourceControl","Misc","SU_Depreciate")))
	
	/***********************
	  End Indexer Specific code
	************************/
	Quit
Escape(data)
  Quit $TR(data,"\/^|")
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.Routine">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
<p>
Source indexer for Mac routines<br/>
Extracts:
<ol><li>Implemention signatures for highlevel diffs</li>
<li><em>Optionally</em> functional source code lines for full-diff reporting</li>
<li>Creates an summary signature of Routine independent of the order in which line labels are defined</li>
</ol>
Source line leading and trailing whitespace is normalised.<br/>
<h3>Configuration</h3>
To exclude source code from being captured for detailed reports use schedule configuration option IncludeSourceCode=0<br/>
To control which routines are included in each target namespace for analysis 
update the lookup global using Interoperability LookupTables in SMP or directly.
When first run in each namespace the following defaults will be established:
<example>
^ompare("Config","Exclude","%*.mac")=1
^ompare("Config","Exclude","Ens*.mac")=1
^ompare("Config","Exclude","RuleCache.*.mac")=1
^ompare("Config","Exclude","SQLExport*.mac")=1
^ompare("Config","Exclude","GCOM*.mac")=1
^ompare("Config","Exclude","CacheSql*.mac")=1
</example>
Where value "1" means exclude and "0" means include.<br/>
Exclusions can layer for example to exclude all routines with prefix "ompare"
except do include analysis of any routines with prefix "ompareUtil":
<example>
^ompare("Config","Exclude","ompare*.mac")=1
^ompare("Config","Exclude","ompareUtil*.mac")=0
</example>
<h3>Treatment of comments</h3>
Analysis excludes single line comments "//" and ";"<br/>
Single line Text comments (";;") are retained for functional difference.
Excludes multiline comments. This is especially useful where whole line-labels
have been commented out and no longer participate in functional code
Multiline comments expect to start line with "/*" sequence
Multiline comments expect to terminate line with "*/".
<example>
TestRoutine
 //Single comment line discarded
 /* 
  comment line multi 1 discarded
  comment line multi 2 discarded
  comment line multi 3 discarded
  */
 ; comment simple A discarded
 ;; Text comment Retained
 quit
 /*
DiscardLable(y) discarded
  Quit y+y discarded
 */
Retain(z)
  Quit z+z
</example>
Would be treated as:
<example>
TestRoutine
 ;; Text comment Retained
 quit
Retain(z)
  Quit z+z
</example>
<h3>Legacy dot syntax</h3>
Legacy implementation is normalised for spacing as this does not cause funtional
difference.<br/>
<example>
Legacy
[tab][tab]set x=1[space]
[tab]d[space]
[space].[space]s x=2
[tab].d[space]
[tab].[space].s x=3
[space].[space]. (Will be discarded)
[tab].[space].[space]s x=4
[space]Q
</example>
Would be treated as implemented as:
<example>
Legacy
[space]set x=1
[space]d
[space].s x=2
[space].d
[space]..s x=3
[space]..s x=4
[space]Q
</example>
Note empty legacy sequence "[space].[space]." is not carried forward for analysis.<br/>
<h3>Source Control tokens</h3>
Source Control tokens can be suppressed via the Schedule properties:
<ul><li>SrcVersionTokenStart</li>
<li>SrcVersionTokenEnd (Optional)</li></ul>
For source control employing both start and end tokens: 
<example>
 quit "TokenStart /path/to/project/TEST/routinename#23 TokenEnd"
</example>
is replaced with:
<example>
 quit "TokenStart TokenEnd"
</example>
Or for systems that use a single start token and monpolise the rest of the source line
<example>
" ;;TokenStart /path/to/project/TEST/routinename#23"
</example>
is replaced with:
<example>
" ;;TokenStart"
</example>
Signatures are built up for individual line label segments.
A summary signature for routine is also constructed that is independent of 
original line label sequence
</p>]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51898</TimeChanged>
<TimeCreated>64118,44172.791103</TimeCreated>

<Parameter name="DocumentType">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>rou</Default>
</Parameter>

<Method name="IndexNamespace">
<Description>
Main entry point for Routine Source Handler</Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	#define RPTType "R"
	#define RPTSubTypeLineLabel "L"
	#define RPTSubTypeConfig "CFG"
	#define RPTItemConfigMapped "IsMapped"
	#define RPTItemConfigSourceControlled "IsSourceControlled"
	#define RPTItemConfigSourceVersion "SrcVer"
	
	if '$IsObject(schedule) {
		set schedule=##class(ompare.Schedule).%New()
	}
	// Testing
    // Do ##class(ompare.SourceHandler.RoutineDefinition).IndexNamespace("USER",0,0)
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace="" $$$ERROR(5001,"Namespace not supplied to Routine Source Handler")
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret
    
	
	// Invoke sub-class extension code
	try {
		Do IndexerMain
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.RoutineDefinition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	Quit ret
SetIsMapped(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:'##class(%Dictionary.CompiledMethod).%ExistsId("%Studio.SourceControl.ISC||IsMapped")
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigMapped)=##class(%Studio.SourceControl.ISC).IsMapped(typeName_".MAC")
	quit
SetIsSourceControlled(typeName="")
	quit:$$$RPTType=""
	quit:typeName=""
	quit:$Data(^Sources)<11
	quit:$$SourceControlClass^%occLibrary($Namespace)'="%Studio.SourceControl.ISC"
	// Assumes if the source control file is present on the filesystem then it is being source controlled
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceControlled)=##class(%File).Exists(##class(%Studio.SourceControl.ISC).ExtName(typeName_".MAC"))
	quit
SetSourceVersion(typeName,data)
	quit:$$$RPTType=""
	quit:typeName=""
	set data=$ZSTRIP(data,"<>W")
	set:$E(data,1)=":" data=$ZSTRIP($E(data,2,*),"<>W")
	quit:data=""
	// Requires both 3rd and 4th key to reuse generic export / import mechanism
	set ^||Data($$$RPTType,typeName,$$$RPTSubTypeConfig,$$$RPTItemConfigSourceVersion)=data
	quit
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  // Intercept Source Control Tokens
  // eg: $I + d: //some/org/project/product/BASE/rtn/PRTDR9ORG.rtn#1 $
  // Converts to $I + d$
  set dataNoTokenVersion=""
  if schedule.SrcVersionTokenStart'="" {
	if schedule.SrcVersionTokenEnd'="" {
		set pattern=".E1"""_schedule.SrcVersionTokenStart_"""1.E1"""_schedule.SrcVersionTokenEnd_""""
  		for {
		  quit:data'?@pattern
		  s dataNoTokenVersion=dataNoTokenVersion_$P(data,schedule.SrcVersionTokenStart)_schedule.SrcVersionTokenStart_schedule.SrcVersionTokenEnd
		  set data=$P($P(data,schedule.SrcVersionTokenStart,2,999999),schedule.SrcVersionTokenEnd,2,999999)
	  	}
	} elseif data[schedule.SrcVersionTokenStart {
		// The source control token effectively matches to the end of the line
		set data=$P(data,schedule.SrcVersionTokenStart)	
	}
  }
  // Include remainder of line after token end if token version content removed
  set:$L(dataNoTokenVersion)>0 data=dataNoTokenVersion_data
  
  
  // strip any terminating whitespace from line
  set data=$ZSTRIP(data,">W")
  // reformatting lines
  // convert leading whitespace (Space / tab)
  // strip space between formatting dots "."
  // [Tab][Tab].[space].[space].[space]if x=123
  // becomes
  // [space]...if x=123
  set writeLineCounter=0
  set writeLineData=""
  set writeLineAtCommand=0
  set writeLineLength=$L(data)
  for writeLineCounter=1:1:writeLineLength {
	  quit:writeLineAtCommand
	  set writeLineChar=$E(data,writeLineCounter)
	  set writeLineChar=$ZSTRIP(writeLineChar,"*W")
	  if writeLineChar="" {
		 set:writeLineCounter=1 writeLineData=" " // Add single space to beginning of the line
	  }
	  // else will be ignoring additional whitespace prefix or interleaving dot white space
	  continue:writeLineChar=""
	  set writeLineData=writeLineData_writeLineChar  // append dot or other command character
	  set:writeLineChar'="." writeLineAtCommand=1
	  quit:writeLineChar'="."  // prevent loop incrementing writeLineCounter
  }
  // append the end of the line
  set:writeLineCounter<=writeLineLength writeLineData=writeLineData_$E(data,writeLineCounter+1,*)
  
  // Ignore Empty Lines
  Quit:writeLineData=""
  
  // Ignore non-function empty dot indented lines
  Quit:writeLineData?1" "."."
  
  // Junk comment lines with optional dots?
  Quit:writeLineData?1" "."."1(1";",2"/").E
  
  // TODO support multi-line comments. /*  comment */ style

  Do tmpStream.WriteLine(writeLineData)
  Do:includeSource AddLine($I(line),writeLineData)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value="")
	W !,label,":",value
	Quit
IsExcluded(name,reason)
	Quit:name="" 1
	// Change the type extension to uppercase 
	set extension=$ZCVT($P(name,".",$L(name,".")),"L")
	set name=$e(name,1,*-($L(extension)+1))
	// Check Exact match for exlcusion
	if +$G(^ompare("Config","Exclude",name_"."_extension)) {
		set reason=name_"."_extension
		quit 1	
	} elseif $Data(^ompare("Config","Exclude",name_"."_extension)) {
		// Explicitly NOT excluded
		quit 0	
	}
	// now recursively look to exclude by wildcard match.
	set found=0
	set reason=""
	set prefix=$e(name,1,*-1)_"*"
	for {
		set found=+$G(^ompare("Config","Exclude",prefix_"."_extension))
		set:found reason=prefix_"."_extension
		quit:found
		if $Data(^ompare("Config","Exclude",prefix_"."_extension)) {
			// Explicitly NOT excluded
			quit	
		}
		set prefix=$E(prefix,1,*-2)_"*"
		q:prefix="*"
	}
	quit found
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/
	// Default exclusions in this namespace
	// Start set once in first run namespace
	set hasConfig=0
	set testExclude=""
	for {
		set testExclude=$O(^ompare("Config","Exclude",testExclude))
		quit:testExclude=""
		if $E(testExclude,*-3,*)=".mac" {
			set hasConfig=1
			quit  // exit on first encountered
		}
	}
	if 'hasConfig {
		// ignore system routines
		set ^ompare("Config","Exclude","%*.mac")=1
		// ignore HealthShare routines
		set ^ompare("Config","Exclude","HS.*.mac")=1
		// ignore Ensemble support routines
		set ^ompare("Config","Exclude","Ens*.mac")=1
		// Ignore Ensemble Generated for Routing Rules
		set ^ompare("Config","Exclude","RuleCache.*.mac")=1
		// Ignore generated
		set ^ompare("Config","Exclude","SQLExport*.mac")=1
		// Routines from TrakCare Generated Layouts
		set ^ompare("Config","Exclude","GCOM*.mac")=1
		// Routines from Dynamic SQL statements
		set ^ompare("Config","Exclude","CacheSql*.mac")=1
	}
	// End set once in first run namespace

	set routinename=""
	for {
		set routinename=$Order(^rMAC(routinename))
		quit:routinename=""
		
		if (routinename?1.E1".G"1.N) {
			// Ends in *.G + numeric. Supports SQL projection
			Do:logging Log("Ignoring """_routinename_""" ends with",".G + numeric")
			continue
		}
		if $$IsExcluded(routinename_".mac",.reason) {
			Do:logging Log("Ignore """_routinename_""" matches filter",reason)
			continue	
		}		
		// Simple - Reindex ALL routines on demand
		Do:logging Log("ProcessRoutine",routinename_$C(13,10))
		
		Do IndexRoutine(routinename,tmpStream,includeSource)
	}
	Quit
IndexRoutine(routinename,tmpStream,includeSource)
	Quit:routinename=""
	Quit:'$IsObject(tmpStream)
	
	Do tmpStream.Clear()
	
	// Replace existing data
	set line=0
	
	//set seq=routinename_$C(10)
	set lineNumber=0
	set currentLabel=routinename  // Typical M convention
	set currentLabelData=""
	set isMultiLineComment=0
	for {
		set lineNumber=$Order(^rMAC(routinename,0,lineNumber),+1,data)
		// There is additional routine information following the Routine lines which are ignored
		quit:lineNumber'?1.N
		
		set tmpdata1=$ZSTRIP(data,"<>W")
		// Simple handling for multiline comments
		// assumes first two characters on line for start multiline comment is "/*"
		// and end two characters for end multiline comment is "*/"
		// Utility is to skip commented-out line labels to pick these up as content difference
		if 'isMultiLineComment,$E(tmpdata1,1,2)="/*" {
			// Start of multiline comment
			set isMultiLineComment=1
			continue
		} elseif isMultiLineComment,$E(tmpdata1,*-1,*)="*/" {
			// End of multiline comment
			set isMultiLineComment=0
			continue	
		} elseif isMultiLineComment	{
			// Continue multiline comment
			continue	
		}
		
		set data=$ZSTRIP(data,">W")
		continue:data=""
		if $E(data,1)?1(1A,1"%") {
		  // Process as Start of Line Label	
		  // Get the line label name
		  set nextLabel=""
		  for i=1:1:32 {
			 set char=$E(data,i)
			 quit:char=""
			 if i>1,char?1P quit
			 // Append character to next linelabel name
			 set nextLabel=nextLabel_char
		  }

		  if nextLabel'=currentLabel,tmpStream.Size>0 {
			
			Do tmpStream.Rewind()
			set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
			Do SetSignature(routinename, sig,$$$RPTSubTypeLineLabel,currentLabel)
			Do:includeSource SaveLines(sig)
			
			set currentLabel=nextLabel
			// Logging
			Do:logging tmpStream.Rewind()
			Do:logging tmpStream.OutputToDevice()
			
			Do tmpStream.Clear()
			set line=0
			Do WriteLine(tmpStream,data)
			
		  } else {
			Do WriteLine(tmpStream,data)
		  }
		  
		} else {
			set tmpdata1=$ZSTRIP(data,"<W")
			if tmpdata1="" {
				continue
			}
			if $E(tmpdata1,1)=";",$E(tmpdata1,2)'=";" {
				// Exclude single line comment except when used
				// as TEXT comments which may have functional differences between code
				continue
			}
			if $E(tmpdata1,1,2)="//" {
				continue
			}
			Do WriteLine(tmpStream,data)
		}
	
	}
	if currentLabel'="",tmpStream.Size>0 {

		Do tmpStream.Rewind()
		set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
		Do SetSignature(routinename, sig,$$$RPTSubTypeLineLabel,currentLabel)
		Do:includeSource SaveLines(sig)
		
		Do tmpStream.Clear()
	}
	
	set routineSummary=routinename
	// After completing detail for line labels make a signature for the whole routine
	// Note that the order of the line labels is not functionally important
	set currentLabel=""
	for {
		Quit:'$$NextSignature(routinename,.sig,$$$RPTSubTypeLineLabel,.currentLabel)
		set routineSummary=routineSummary_";"_currentLabel_":"_sig
	}
	
	Do SetSignature(routinename, $SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1Hash(routineSummary)))
	
	Do SetIsMapped(routinename)
	Do SetIsSourceControlled(routinename)
	// Exit Line label
	Quit

	/***********************
	  End Indexer Specific code
	************************/
	Quit
]]></Implementation>
</Method>
</Class>


<Class name="ompare.SourceHandler.SQLTable">
<Description><![CDATA[
<pre>
Copyright (c) Alex Woodhead 2020

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

License MIT
Source: https://github.com/alexatwoodhead/ompare
Version: 1.0
</pre>
Generic Utility to profile any data with SQL Table projection.<br/>
For example ScheduleTasks and Production Settings can be exposed for easy comparison across environments.
For example an application may contain many configuration tables, where some comparison between environments is needed.
Specific columns of interest can be selected.
Columns with sensitive information can be ignored.
Instance specific values (numeric RowId, timeadded / created) can be excluded from sampling.
Simple filtering record on column values is also supported.
ie: For a row to be sampled one or more columns require specific values.<br/>
One or more columns are used as a unique composite key to identify a row.
Extracted rows are sorted by this chosen unique composite key.
Opt-in profiling</br>
Rules for what and how to profile are stored on target system in Ensemble Lookup SourceCompareSQL
<example>
^ompare("Config","SQL", Key[*] + [ "," + Alias ]) = enabled + "," + maxRows + "," + idSpec + "," + rowSpec
</example>
Key Structure. Delimited by ","
<table class="Summary">
  <tr>
    <th>Key</th>
    <th>Alias</th> 
  </tr>
  <tr>
    <td>Table name</td>
    <td>Mandatory<br/>
        Can be an exact name of SQL Table OR<br/>
        have a "*" Wild Card suffix to include multiple tables
    </td>
  </tr>
  <tr>
    <td>Alias name</td>
    <td>Optional<br/>
        Allows multiple rule configurations to be processed for the same table(s)
    </td>
  </tr>
</table>
Value structure. Delimitied by ","
<table class="Summary">
  <tr>
    <th>Name</th>
    <th>Comment</th> 
  </tr>
  <tr>
    <td>Enabled</td>
    <td>"0" (Do not Profile) OR<br/>
        "1" (Do Profile)</br>
        Useful to toggle whether a sample rule is active or not
    </td>
  </tr>
  <tr>
    <td>ExportValues</td>
    <td>Controls whether Values are exported for detailed pre-record comparison on diff-report service.
        "" empty means use the <em>IncludeSourceCode</em> flag provided by Schedule to determin whether column values should be exported or not.<br/>
		"0" means NEVER export column values. Only export the signature of values. Overrides <em>IncludeSourceCode</em> flag on Schedule.<br/>
        "1" means always export column values along with the signature of values. Overrides <em>IncludeSourceCode</em> flag on Schedule.</br>
        Useful to guard against unintended information sharing.
    </td>
  </tr>
  <tr>
    <td>Max Rows</td>
    <td>Numeric number of records to capture for sample. Defaults to first 1000 processed<br/>
    </td>
  </tr>
  <tr>
    <td>Id Spec</td>
    <td>One or more column Names delimited by "~" when combined are used as a unique "ID".<br/>
        By default will use "%ID"<br/>
        For example if the column "Name" contains unique values, but the source table also has a numeric row ID
        The "Name" column is used and the "ID" column is suppressed from the sample.
        The sample rows will be sorted on "Name".<br/>
        This allows effective differencing of records, that may have been inserted into different environments, in a different insert order with different source numeric IDs
    </td>
  </tr>
  <tr>
    <td>rowSpec</td>
    <td>One or more columns to sample.<br/>
        Delimited by "~"<br/>
        "*" Wild card to just include all columns. Default vaue.<br/>
        Exact column names can be specified (Case insensitive)<br/>
        Wild card suffix can be used on column name for example "Address*" would match "AddressLine1" and "AddressLine2"<br/>
        "-" minus prefix negates inclusion of a column. For example: "-Address*" would exclude columns "AddressLine1" and "AddressLine2"<br/>
        The syntax is clumulative so: "*~-Address*" would mean include ALL columns but not "AddressLine1" or "AddressLine2"
    </td>
  </tr>
  <tr>
    <td>Filter</td>
    <td>One or more expressions to filter out unwanted records.<br/>
Delimited by "~"<br/>
By default conditions operate with an implicit "OR" mode.
<example>
Name=Switch Journal~Name=Purge Tasks
</example>
Meaning: Where the Name column has the value "Switch Journal" OR "Purge Tasks" then include in sample.<br/>
To combine multiple conditions, prefix the series of subsequent columns with "&"
<example>
ID>5~&ID<10
</example>
Meaning: Where the ID column has values between 6 and 9<br/>
Note the AND sequence operates in groups so that
<example>
ID>2~&ID<5~ID>9~&ID<15
</example>
Meaning: Where the ID column has values (between 3 and 4) OR (between 10 and 14) then include in sample.<br/>
The following filter operators are currently supported.
<ul><li>"<" - Less than</li>
<li>">" - More than</li>
<li>"!=" - Not Equal</li>
<li>"=" - Equal</li>
<li>"![" - Does not contain</li>
<li>"[" - Contains</li>
</ul>
    </td>
  </tr>
</table>
<h3>Example configuration</h3>
The following examples demonstrate configurations using existing Scheduled Tasks.
Global view for Key and Value.
<example>
set ^ompare("Config","SQL","%SYS.Ta*,TaskA")="1"
</example>
<table class="Summary">
  <tr>
    <th>Key</th>
    <th>Value</th>
    <th>Meaning</th>
  </tr>
  <tr>
   <td>%SYS.Ta*,TaskA</td>
   <td>1</td>
   <td>Using wildcard on source Table name.
       Matches multiple SQL Tables with name starting with "%SYS.Ta".<br/>
       These resolve to "%SYS.Task" and "%SYS.TaskSuper"
       Enabled Profile.<br/>
       Default return maxRows 1000.<br/>
       Default IDSpec "%ID".<br/>
       Default "*" return all columns.
    </td>
  </tr>
  <tr>
    <td>%SYS.Task</td>
    <td>1,100,Name,Description~TaskClass</td>
    <td>Match exactly one SQL Table with name <em>%SYS.Task</em>.<br/>
        Enabled Profile.<br/>
        Return only first 100 rows.<br/>
        Use <em>Name</em> column as sample row ID.<br/>
        Only return values for columns Description and TaskClass
    </td>
  </tr>
  <tr>
    <td>%SYS.Task,Scheduled Tasks</td>
    <td>1,500,Name,*~-ID,-Display*</td>
    <td>Match exactly one SQL Table with name %SYS.Task.<br/>
        Use an Alias of "Scheduled Tasks" for this table rule.
        Allows previous defined rule for this table to also be processed independently.<br/>
        Enabled Profile.<br/>
        Return only 500 rows.<br/>
        Use <em>Name</em> column as sample row ID.<br/>
        Return ALL columns BUT exclude the ID column.
        Also exclude any columns that startwith Display for example: DisplayDayNextScheduled,
 DisplayEndDate, DisplayErrorDate, DisplayErrorNumber, DisplayFinished, DisplayInterval
 DisplayNextScheduled, DisplayNextScheduledBrief, DisplayRun, DisplayRunAfter, DisplayStartDate
 DisplayStarted, DisplayStatus
    </td>
  </tr>
</table>	]]></Description>
<Super>ompare.SourceHandler.Base</Super>
<TimeChanged>66487,51907</TimeChanged>
<TimeCreated>64751,42188.599008</TimeCreated>

<Parameter name="TypeCode">
<Description>
Ensure this Code doesn't collide with other sub-class implementations of Base
Eg: "CLS" abbreviation for class</Description>
<Type>%String</Type>
<Default>SQL</Default>
</Parameter>

<Method name="IndexNamespace">
<Description><![CDATA[
<!--
Do not invoke supporting methods on this class definition
do ##class(ompare.SourceHandler.SQLTable).IndexNamespace($Namespace,1)
set ^ompare("Config","SQL","%SYS.Task,ScheduleTasks")="1,1,,Name,Description~TaskClass~RunAsUser,Name=Switch Journal~Name=Purge Tasks"
set ^ompare("Config","SQL","%SYS.Task,ScheduleTasks")="1,1,,Name,Description~TaskClass~RunAsUser,Name=Switch Journal~&TaskClass="%SYS.Task.PurgeTaskHistory~Name=Purge Tasks~&TaskClass="%SYS.Task.PurgeTaskHistory"
set ^ompare("Config","SQL","%SYS.Task,ScheduleTasks")="1,1,,ID~Name,Description~ID~TaskClass~RunAsUser,ID>5~&ID<9"
set ^ompare("Config","SQL","%SYS.Task,ScheduleTasks")="1,1,,Name,Description~ID~TaskClass~RunAsUser,TaskClass[Purge"
set ^ompare("Config","SQL","%SYS.Task,ScheduleTasks")="1,1,,Name,Description~ID~TaskClass~RunAsUser,TaskClass![Purge"
s g="^||DataSrc" f{s g=$Q(@g)  q:g=""  W !,@g} -->]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>namespace="",logging=0,includeSource=0,schedule:ompare.Schedule=$$$NULLOREF</FormalSpec>
<ReturnType>%Status</ReturnType>
<Implementation><![CDATA[
	set overrideIncludeSource=includeSource
	#define RPTType "SQL"
	
	/*****************************
	 Start Template
	******************************/
	#dim tmpStream as %Stream.TmpCharacter
	Set tmpStream=##class(%Stream.TmpCharacter).%New()
	// It is necessary to switch namespace context within the method call as source code may not be 
	// deployed to target namespace
	set ret=$$$OK
	
	Quit:namespace=""
	
	New $NAMESPACE  // Ensures when method exits process will be returned to the original namespace
	
	try {	
		 // Generates <NAMESPACE> error if namespace doesn't exist
		 // Generate <PROTECT> error if user does not have access privilage
		set $NAMESPACE=namespace
	} catch errobj {
		// Name
		// Code
		// Location
		// Data
		if errobj.Name="<NAMESPACE>" {
			set ret=$$$ERROR(5001,"Cannot index namespace "_namespace_". Namespace does not exist.")
		} elseif errobj.Name="" {
			set ret=$$$ERROR(50001,"Cannot index namesapce "_namespace_". User "_$USERNAME_" does not have permission.")
		} else {
			set ret=$$$ERROR(5001,"Unknow error "_errobj.Name_". In code "_errobj.Code_" at location "_errobj.Location)
		}
	}
	Quit:$$$ISERR(ret) ret

	try {
		// Invoke sub-class extension code
		Do IndexerMain
	} catch ex {
		// Always report issue in output
		Do Log("Error","In SourceHandler.ClassDefinition")
		Do Log("  Name:",ex.Name)
		Do Log("  Code:",ex.Code)
		Do Log("  Location:",ex.Location)
		Do Log("  Data:",ex.Data)
		Set ret=ex.AsStatus()
	}
	
	Quit ret
SetSignature(typeName="", signature="",subTypeCode="", subTypeName="")
	Quit:$$$RPTType=""
	Quit:typeName=""
	Quit:signature=""
	if subTypeCode'="",subTypeName'="" {
		set ^||Data($$$RPTType,typeName,subTypeCode,subTypeName)=signature
	} else {
		set ^||Data($$$RPTType,typeName)=signature
	}
	quit
	// To itterate on the names and signatures of a particular subType
	// pass typeName by value required
	// pass signature by reference
	// pass subTypeCode by value required
	// pass subTypeName by reference required
NextSignature(typeName,signature,subTypeCode, subTypeName)
  set signature=""
  // subTypeName may be empty string at start of itteration
  Quit:typeName="" 0
  Quit:subTypeCode="" 0
  set subTypeName=$Order(^||Data($$$RPTType,typeName,subTypeCode,subTypeName),+1,signature)
  Quit:subTypeName="" 0 
  Quit 1
  // Write to stream AND conditionally to DataSrc
WriteLine(stream,data)
  // No Source Control Tokens to intercept
  Do tmpStream.WriteLine(data)
  Do:overrideIncludeSource AddLine($I(line),data)
  Quit
AddLine(line,data)
  Quit:+line=0
  // remove previous data
  if line=1 {
	 kill ^||DataSrcTmp
	 set ^||DataSrcTmp=+$H
  }
  set ^||DataSrcTmp(line)=data
  Quit
SaveLines(sig="")
  quit:sig=""
  if $Data(^||DataSrc(sig)) {
	// if the source record already exists simply update the last referenced date to today
	set ^||DataSrc(sig)=+$H
  } else {
	merge ^||DataSrc(sig)=^||DataSrcTmp
	Kill ^||DataSrcTmp
  }
  Quit 1
Log(label, value)
	W !,label,":",value
	Quit
	
IndexerMain
	/*****************************
	 End Template
	 Add sub-class code and supporting line labels from this point forward.
	******************************/
	
	
	// Initialise process
	Kill ^||SQLTableNames,^||SQLTableNamesMatched
	
	// First we create a list of SQL tables that extend %Persistent
	set rs=##class(%ResultSet).%New()
	set rs.ClassName="%Dictionary.ClassDefinitionQuery"
  	set rs.QueryName="SubclassOf"
  	set tSC=rs.Execute("%Persistent")
  	if $$$ISERR(tSC) {
	 	do Log("Error","In SourceHandler.SQLTable. Unable to run %Persistent Query")
	 	quit
  	}
  	for {
		quit:'rs.Next()
  		//
  		set classname=$Get(rs.Data("Name"))
  		continue:classname=""
  		
  		set classdef=##class(%Dictionary.ClassDefinition).%OpenId(classname,0)
  		continue:'$IsObject(classdef)
  		continue:classdef.Abstract=1  // Ignore template classes
  		
  		set sqlTable=$$GetSQLTableName(classname)
  		continue:sqlTable=""
  		// Add to available SQL Tables on the system
  		set ^||SQLTableNames(sqlTable)="" 		
  	}
  	set classdef=""
	
	set tableAndAlias=""
	for {
		set tableAndAlias=$Order(^ompare("Config","SQL",tableAndAlias),+1,rules)
		quit:tableAndAlias=""
		
		// Check rule is enabled
		if '+rules {
			do Log("Info","Ignoring disabled SQL Table and Alais "_tableAndAlias)
			continue	
		}
		// Only process enabled search mask
		//do Log("Info","Processing enabled SQL Table and Alais "_tableAndAlias)
		Do MatchSQLTables(tableAndAlias,rules)	
	}
	set table=""
	for {
		// table variable will be SQL Table name with optional Alias Name
		// delimted by comma
		// This is to support multiple rule profiles for a single table
		set table=$O(^||SQLTableNamesMatched(table))
		quit:table=""
		set alias=""
		for {
			set alias=$O(^||SQLTableNamesMatched(table,alias),1,rules)
			quit:alias=""
			do Log("Info","Processing enabled SQL Table and Alais "_table_" ("_alias_")")
			do IndexSQLTable(table,alias,rules)
		}
	}
	
	// For each matched SQLTable
	// Run extract based on mask parameters
	
	//Do Log("Start",$ZDT($H,3))
	//Do SetSignature("Class1","sig")
	//Do SetSignature("Class1","sig","PROP","TESTPROP")
	//Do Log("End",$ZDT($H,3))
	/***********************
	  End Indexer Specific code
	************************/
	// Tidy up
	Kill ^||SQLTableNames
	Kill ^||SQLTableNamesMatched
	
	Quit
 // Returned the explicit SQL Table name from a class
 // or derives the SQL name that would be used
GetSQLTableName(classname)
	set sqlTable=""
	// Derive SQLTable Name from Classname
  	set sqlTable=classdef.SqlTableName
  	if sqlTable="" {
		// Replace Dot "." for "_" underscore in package name
		set sqlTable=$Tr($P(classname,".",1,$L(classname,".")-1),".","_")_"."_$P(classname,".",$Length(classname,"."))
		// Replace prefix "User" with "SQLUser" for default user table schema
		set:$P(sqlTable,"_")="User" sqlTable="SQLUser_"_$P(sqlTable,"_",2,99)
		// Replace "%" System class prefix with "_" underscore
		//set:$E(sqlTable,1)="%" sqlTable="_"_$E(sqlTable,2,*)
  	}
  	quit sqlTable
 // Sub-Routine that creates a list of SQL Tables
 // That match the given prefix mask
 // Adds entries to process private global ^||SQLTableNamesMatched
 // Do not clear existing entries
 // Only invoked for pattern that is enabled
MatchSQLTables(tableAndAlias,rules)
 set mask=$ZSTRIP($P(tableAndAlias,",",1),"*W")
 set alias=$ZSTRIP($P(tableAndAlias,",",2),"*W")
 set:alias="" alias="_"
 quit:mask=""
 if $E(mask,*)="*" {
	 set (start,next)=$E(mask,1,*-1)
	 // We don't do ALL tables??
	 quit:start=""
	 set startLen=$length(start)
	 
	 if $Data(^||SQLTableNames(start)) {
		// Might as well just set matching rules here
		set ^||SQLTableNamesMatched(start,alias)=rules
	 }
	 
	 for {
		set next=$Order(^||SQLTableNames(next))
		quit:next=""
		// Moved past wild card include section
		quit:start'=$E(next,1,startLen)
		// Check Match is enabled
		set ^||SQLTableNamesMatched(next,alias)=rules
	 }
 } else {
	 // Exact Match
	 if $Data(^||SQLTableNames(mask)) {
		set ^||SQLTableNamesMatched(mask,alias)=rules
	 }
 }
 quit
 // Adds record to temporary area for sorting by record ID
SortNVP(key,value)
 if key="" {
	 Do Log("ERROR","SortNVP Key="_key_" was empty")
	 Quit
 }
 if $Data(^||NVP(key)) {
	 Do Log("ERROR","SortNVP Duplicate Key """_key_""" detected."_$C(10)_"  Existing value="_$G(^||NVP(key))_"."_$C(10)_"  New value="_value)
	 Quit	 
 }
 Do:logging Log("INFO","SortNVP Key="_key_";value="_value)
 set ^||NVP(key)=value
 Quit
 // Outputs ID ordered records into Stream for signature and source output
FlushNVP(oKey,oData)
 set key=""
 for {
	set key=$O(^||NVP(key),1,data)
	quit:key=""
 	Do WriteLine(tmpStream,key_"¬"_data)
 }
 //Kill ^||NVP
 Do tmpStream.Flush()
 Quit
FilterUnknown(FilterUnknownVal, FilterUnknownUnknown = "?",oFilterUnknownUnknownRep)
 set oFilterUnknownUnknownRep="",$P(oFilterUnknownUnknownRep,FilterUnknownUnknown,32)=""
 quit $TR(FilterUnknownVal,$C(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31),oFilterUnknownUnknownRep)
 // <example>
 // Set val=$LB(123,$$LB(
 // Do ##class(ompare.SourceHandler.SQLTable).ToString(val)
 // </exampe>
 // Recursive normalisation of List Columns for embedded objects in SQL
 // The Binary data via GZIP stream causes issues for loading data on target report service
ToString(pToStringVal, pToStringDelim1 = "#", pToStringDelim2 = "@", pToStringUnknown = "?", pToStringStop = 0,oRet,oLl,oI,oListItem)
  set oRet=""
  if $Listvalid(pToStringVal) {
    set oLl=$LISTLENGTH(pToStringVal)
    for oI=1:1:oLl {
      set oListItem=$ListGet(pToStringVal,oI,"")
	  if $Listvalid(pToStringVal) {
	    set oListItem=$$ToString(oListItem,pToStringDelim2,"[",pToStringUnknown)	
	  }
	  set oRet=oRet_$S(oI=1:"",1:pToStringDelim1)_$$FilterUnknown(oListItem,pToStringUnknown)
    }
  } else {
    set oRet=$$FilterUnknown(pToStringVal,pToStringUnknown)	
  }
  quit oRet

 // For each SQL Table of interest
 // process the rules
IndexSQLTable(sqlTable,sqlTableAlias,rules,writeHeaders=1)
 Kill ^||NVP
 Do:logging Log("INFO","Invoke IndexSQLTable with table="_sqlTable_";alias="_sqlTableAlias_";rules="_rules)
 quit:sqlTable=""
 quit:rules=""
 Do tmpStream.Rewind()
 Do tmpStream.Write("")  // Attempt to truncate prior content
 Do tmpStream.Flush()
 Do tmpStream.Clear()
 set line=0
 // Initilaise
 kill cols,colsU,colsUse
 
 //set indexParameters=$Get(^ompare("Config","SQL",rules))
 set overrideIncludeSource=$Piece(rules,",",2)
 if $Piece(rules,",",2)="" {
	 set overrideIncludeSource=includeSource
 }else {
	 set overrideIncludeSource=+$Piece(rules,",",2)
 }
 set maxRows=+$Piece(rules,",",3)
 set:maxRows<1 maxRows=1000
 set idSpec=$Piece(rules,",",4)
 set ideSpecLen=$L(idSpec)
 set rowSpec=$Piece(rules,",",5)
 kill filter set filter=$Piece(rules,",",6)
 set filterCount=0,filterGroup=0
 set filterLen=$L(filter,"~")
 for {
	set filterCount=filterCount+1
	quit:filterCount>filterLen
	set filterData=$P(filter,"~",filterCount)
	
	set operatorPos=9999,operatorNext=0,operatorUse=""
	for operator="<",">","!=","=","![","[" {
		set operatorNext=$F(filterData,operator)
		if operatorNext>0,operatorNext<operatorPos {
			set operatorUse=operator
			set operatorPos=operatorNext
		}
}
	continue:operatorPos=9999
	continue:operatorUse=""
	// Support comparison operators
	// < - less than 
	// > - more than
	// =
	// Support multiple constraints on same column for range query
	// set filter("Age",">",18)=""
	// set filter("Age","<",67)=""
	
	// set filter(filterKey,operator,filterVal)=""
	// 
	
	set filterKey=$ZSTRIP($P(filterData,operatorUse),"<>W")
	continue:filterKey=""
	continue:filterKey="&"
	if $E(filterKey,1)="&" {
		// composite condition
		set filterKey=$E(filterKey,2,*)
	} else {
		set filterGroup=filterGroup+1	
	}
	set filterVal=$ZSTRIP($P(filterData,operatorUse,2,99),"<>W")
	set:filterVal="" filterVal=$C(0) // Support null or empty values
	// All operators MUST match within a given filterGroup
	set filter(filterGroup,filterKey,operatorUse,filterVal)=""
 }
 set:rowSpec="" rowSpec="*"
 // SQL names are case insensitive
 set rowSpec="~"_$ZCVT(rowSpec,"U")_"~"
 set rowSpecLen=$L(rowSpec,"~")
 // Reset from any previous invocation
 kill idList,idSeq
 set idList="",idSeq=0
 for i=1:1:ideSpecLen {
	set id=$ZCVT($ZSTRIP($P(idSpec,"~",i),"*W"),"U")
	continue:id=""
	//set idList=$S($L(idList)=0:"",1:",")_idList  // creating a list of items to slect for 
	set idList(id)=""  // Used to filter out Value Columns where Information is already part of the Key Columns
	set idSeq($I(idSeq))=id  // Used to assemble SubKeys in correct order of rule definition
 }
 // if no ID columns are explicitly defined in the rules
 // then fallback to defaults
 if idSeq<1 {
	 
	 set idList("ID")=""
	 set idSeq(1)="ID"
	 set idListM("ID")="ID"
 }
 
 set rs=##class(%ResultSet).%New("%DynamicQuery:SQL")
 // Decide what the columns are and pre-filter on SQL statement
 //   OR
 // Use select ALL approach
 // ******************
 // TODO - TABLE may have ALIAS defined for IT - Strip ALIAS for select??
 // TODO - Rows to Select??
 
 // MUST NOT LOCK
 set sqlStatement="SELECT %NOLOCK %ID as ID,* FROM "_sqlTable
 set sc=rs.Prepare(sqlStatement)
 Do:logging Log("INFO",sqlStatement)
 if $$$ISERR(sc) {
	Do:logging Log("Error","Unable to Prepare Statement for table "_sqlTable_$Select(sqlTableAlias'="":" as Alias "_sqlTableAlias))
	set rs=""
	quit
 }
 set sc=rs.Execute()
 if $$$ISERR(sc) {
	Do:logging Log("Error","Unable to Execute Statement for table "_sqlTable)
	set rs=""
	quit
 }
 
 // Process Headers
 // On the frist row of the returned resultset extract the headers to create a header record
 
 // Calculate Row Headers for inclusion or exclusion
 // Expand columns to use
 // Case insensitive search for column filtering

 set colCount=rs.GetColumnCount()	
 
 set col=""
 for k=1:1:colCount {
	set col=rs.GetColumnHeader(k)
 	//set col=$O(rs.Data(col))
	continue:col=""
	// If this is not an ID column add for value columns
	if '$Data(idList($ZCVT(col,"U"))) {
		//set:col'?1(1"ID",1.N1".ID") cols(col)=""  // Actual Case names
		//set:col'?1(1"ID",1.N1".ID") colsU($ZCVT(col,"U"))=col  // Capture case insensitive
		//set:col'?1(1"ID",1.N1".ID") cols(col)=""  // Actual Case names
		//set:col'?1(1"ID",1.N1".ID") colsU($ZCVT(col,"U"))=col  // Capture case insensitive
		set:col'?1(1.N1".ID") cols(col)=""  // Actual Case names // Allow ID in Values
		set:col'?1(1.N1".ID") colsU($ZCVT(col,"U"))=col  // Capture case insensitive // Allow ID in Values
	} else {
		set idListM($ZCVT(col,"U"))=col  // Builds a link between case insensitive 	
	}
 }

 if rowSpec["~*~" {// WildCard expand all
	Do:logging Log("INFO","WildCard pattern ""*"" detected expand ALL")
	merge colsUse=colsU  // Does not contain ID columns

 }
 for i=1:1:rowSpecLen {
	set (scol,mcol)=$ZSTRIP($ZCVT($Piece(rowSpec,"~",i),"U"),"*W")
	continue:mcol=""
	continue:mcol="-"
	continue:mcol="*"
	set:$E(scol,1)="-" (scol)=$E(scol,2,*)
	set:$E(scol,*)="*" (scol)=$E(scol,1,*-1)
		
	// exact column match
	if $E(mcol,*)="*" {
		Do:logging Log("INFO","Wild Card match on pattern "_mcol)
		set colStartLen=$Length(scol)
		
		set col=scol
		for {
			set col=$O(colsU(col),1,colMixed)
			quit:col=""
			quit:$E(col,1,colStartLen)'=scol
			// Remove filtered out columns
			if $E(mcol,1)="-" {
				Do:logging Log("INFO","Remove column "_col_" matches "_mcol)
				kill cols(colMixed)
				kill colsU(col)
				kill colsUse(col)
				continue
			} else {
				Do:logging Log("INFO","Include column "_col_" matches "_mcol)
				// Include filtered in columns
				set colsUse(col)=colMixed
				continue
			}
		}
	}
	// If the exact match exists as a column then process it
	if $Data(colsU(scol)) {
		Do:logging Log("INFO","Exact Match on column "_scol_" with match pattern "_mcol)
		set colMixed=$G(colsU(scol))
		if $E(mcol,1)="-" {
			Do:logging Log("INFO","Exclude Single column "_scol_" matches "_mcol)
			kill:colMixed'="" cols(colMixed)
			kill colsU(scol)
			//kill colsUse(scol,"U")
			kill colsUse(scol)
		} else {
			Do:logging Log("INFO","Include Single column "_scol_" matches "_mcol)
			set:colMixed'="" colsUse(scol)=colMixed
		}
	}
 }
	
	// Write Headers
	set col=""
	set key=""
	set data=""
	
	set colSeq=""
	for {
		set colSeq=$O(idSeq(colSeq),1,col)
		quit:colSeq=""
		Do:logging Log("INFO","colSeq "_colSeq_";col="_col)
		set mcol=$G(idListM(col)) // Same as colMixed
		// unexpected - Bad rule configuration
		if mcol="" {
			Do:logging Log("ERROR","Cannot find ID column "_mcol_" in match rule ID specification "_idSpec)
			//kill colsUse  // terminate processing
			continue  
		} else {
			Do:logging Log("INFO","Find ID column "_mcol_" in match rule ID specification "_idSpec)
		}
		set:key'="" key=key_"¬"
		set key=key_mcol
	}
	// followed by data column headers
	set col=""
	for {
		set col=$O(colsUse(col),1,colMixed)
		quit:col=""
    	set data=data_"¬"_colMixed  // Headers ID
 	}
		
 	Do:writeHeaders WriteLine(tmpStream,key_"¬"_data)


 // END PROCESS HEADERS
 set rowCount=0
 for {
	if 'rs.Next(.sc) {
		Do:logging Log("ERROR","ResultSet.Next "_$SYSTEM.Status.GetOneErrorText(sc))
		quit
	}
 	set rowCount=rowCount+1
	if rowCount>maxRows {
		Do:logging Log("WARNING","MaxRows "_maxRows_" encounted")
		quit	
	}

 	// Assumes cols collection is set up
 	if '$Data(colsUse) {
		Do Log("WARNING","No records for table")
		quit
	}
	Do:logging Log("INFO","Data Row "_rowCount)
	// for each filter
	set filterAndGroup=0
	// If there are no filters then just include all records for the table
	set filterRecord=$S($D(filter)>1:1,1:0)
	for {
		set pass=1
		set filterAndGroup=$Order(filter(filterAndGroup))
		quit:filterAndGroup=""
		
		set filterItem=""
		for {
			quit:pass=0
			set filterItem=$Order(filter(filterAndGroup,filterItem))
			quit:filterItem=""
			
			set filterOperator=""
			for {
				quit:pass=0
				set filterOperator=$O(filter(filterAndGroup,filterItem,filterOperator))
				quit:filterOperator=""
				
				set filterValue=""
				for {
					quit:pass=0
					set filterValue=$O(filter(filterAndGroup,filterItem,filterOperator,filterValue))
					quit:filterValue=""
					set filterValueTest=filterValue
					set:filterValue=$C(0) filterValueTest=""
					set filterItemData=rs.Data(filterItem)
					if $E(filterValueTest,*)="*" {  // StartWith
						set filterValueTest=$P(filterValueTest,"*")
						set:filterOperator["=" filterItemData=$E(filterItemData,1,$L(filterValueTest))
					} 
										
					// And / Or ??
					//="<",">","!=","=",![,[
					if filterOperator="<" {
						if filterItemData'<filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected less than "_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}
					} elseif filterOperator=">" {
						if filterItemData'>filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected more than "_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}
					} elseif filterOperator="!=" {
						if filterItemData=filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected not equal"_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}
					} elseif filterOperator="=" {
						if filterItemData'=filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected equal"_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}
					} elseif filterOperator="![" {
						if filterItemData[filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected does not contain "_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}	
					} elseif filterOperator="[" {
						if filterItemData'[filterValueTest {
							Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected contains"_filterValue_";Actual="_rs.Data(filterItem))
							set pass=0
							quit  // early exit
						}	
					}
				}
			}
		}
		set:pass filterRecord=0
		/*
		set filterValue=$Get(filter(filterItem))
		
		if rs.Data(filterItem)'=filterValue {
			Do:logging Log("INFO","Filtering out row="_rowCount_";Column="_colMixed_";Expected="_filterValue_";Actual="_rs.Data(filterItem))
			set filterRecord=1	
		} */
	}
	continue:filterRecord
	
	set key=""
	set col=""
	set colSeq=""
	for {
		set colSeq=$O(idSeq(colSeq),1,col)
		quit:colSeq=""
		continue:col=""
		set mcol=$G(idListM(col)) // Same as colMixed
		// unexpected - Bad rule configuration
		if mcol="" {
			Do:logging Log("ERROR","Cannot find ID column "_col_" in match rule ID specification "_idSpec)
			//kill colsUse  // terminate processing
			continue 
		}else {
		}
		set:key'="" key=key_"¬"
		set key=key_$$ToString($G(rs.Data(mcol)))
	}

	 // Assumes cols collection is set up
	quit:'$Data(colsUse)
	set data=""
	set col=""
	for {
		set col=$O(colsUse(col),1,colMixed)
		quit:col=""
		// append build up record
		//continue:col="ID"  // COLS ID in DATA
		set:data='"" data=data_"¬"
		set data=data_"¬"_$$ToString(rs.Data(colMixed))
	}
	
	
 	Do:logging Log("INFO","Call SortNVP rowCount="_rowCount_";key="_key_";value"_data)
	Do SortNVP(key,data)
	//Do WriteLine(tmpStream,key_"¬"_data)
 }
 if $$$ISERR(sc) {
	Do Log("Error","Processing table rowcount "_rowCount)
	set rs=""
	quit
 }
 Do FlushNVP()  // Outputs sorted records to stream
 set sig=$SYSTEM.Encryption.Base64Encode($SYSTEM.Encryption.SHA1HashStream(tmpStream))
 Do SetSignature(sqlTable_$S(sqlTableAlias'="_":" ("_sqlTableAlias_")",1:""), sig)
 Do SaveLines(sig)
 
 quit
]]></Implementation>
</Method>

<UDLText name="T">
<Content><![CDATA[
/*
/// <example>
/// Set val=$LB(123,$$LB(
/// Do ##class(ompare.SourceHandler.SQLTable).ToString(val)
/// </exampe>
/// Recursive normalisation of List Columns for embedded objects in SQL
/// The Binary data via GZIP stream causes issues for loading data on target report service
/// TODO - Move to line label
ClassMethod ToString(val, delim1 = "#", delim2 = "@", unknown = "?", stop = 0)
{
	set ret=""
	if $Listvalid(val) {
		set ll=$LISTLENGTH(val)
		for i=1:1:ll {
			set listItem=$ListGet(val,i,"")
			if $Listvalid(val) {
				set listItem=..ToString(listItem,delim2,"[",unknown)	
			}
			set ret=ret_$S(i=1:"",1:delim1)_..FilterUnknown(listItem,unknown)
		}
	} else {
		set ret=..FilterUnknown(val,unknown)	
	}
	quit ret
}

ClassMethod FilterUnknown(val, unknown = "?")
{
	quit $TR(val,$C(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31),unknown)
}
*/
]]></Content>
</UDLText>

<UDLText name="T">
<Content><![CDATA[
/*
ClassMethod TestToString()
{
	set val="123,456,789"
	if ..ToString(val)'="123,456,789" {
		W !,"Error in Test 1"	
	}
	set val=$LB(123,456,789)
	if ..ToString(val)'="123#456#789" {
		W !,"Error in Test 2"	
	}
	
	set val=$LB(123,$LB(456,789),$LB(10,11,12),$LB(14))
	if ..ToString(val)'="123#456@789#10@11@12#14" {
		W !,"Error in Test 3"	
	}
	set val=$LB(123,$LB(456_$C(13),789_$C(9)),$LB(10_$C(22),11_$C(25),12),$LB(14))
	if ..ToString(val)'="123#456@789#10@11@12#14" {
		W !,"Error in Test 4"	
	}
}
*/
]]></Content>
</UDLText>
</Class>
</Export>
